{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yasminsarkhosh/fyp2021p3/blob/main/FYP_project_3_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fQN_SBG0idm"
   },
   "source": [
    "## Get some images and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8Nv2biGui3u",
    "outputId": "7b569744-dc4a-42b9-e7f4-373dc60a7264"
   },
   "outputs": [],
   "source": [
    "if True:      #A weird trick needed for Google Colab\n",
    "  # Clone repository with example images \n",
    "  !rm -rf fyp2021p3\n",
    "  !git clone https://github.com/vcheplygina/fyp2021p3.git\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Other useful packages might be skimage or PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING IN FILE: EXAMPLE_GROUND_TRUTH.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#read file\n",
    "file_input = pd.read_csv(\"../data/example_ground_truth.csv\")\n",
    "file_input.shape\n",
    "\n",
    "#150 images in total\n",
    "#3 columns: image_id, melanoma, keratosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FRAME FOR EXAMPLE_GROUND_TRUTH FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FRAME FOR IMAGES WITH NO DIAGNOSIS, MEANING MELANOMA AND KERATOSIS == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame for images with no diagnosis\n",
    "non_malignant_df = file_input.loc[(file_input['melanoma'] == 0.0) & (file_input[\"seborrheic_keratosis\"] == 0.0)]\n",
    "non_malignant_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR IMAGES WITH MELANOMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out all images that are not melanoma\n",
    "melanoma = file_input[file_input[\"melanoma\"] == 1.0]\n",
    "\n",
    "#remove column for keratosis\n",
    "melanoma_df = melanoma.drop([\"seborrheic_keratosis\"], axis = 1)\n",
    "melanoma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of images left\n",
    "melanoma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING IN FILE FOR FEATURES.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file features\n",
    "file_features_df = pd.read_csv(\"../features/features.csv\")\n",
    "file_features_df.shape\n",
    "\n",
    "#150 rows, 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame for features\n",
    "file_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data frame for features with data frame for melanoma to filter out non-related images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column 'id' to 'image_id'\n",
    "file_features_df.rename(columns={'id': 'image_id'}, inplace=True)\n",
    "\n",
    "#merge data frame for file_features_df with melanoma by column 'image_id'\n",
    "merge_feature_melanoma = file_features_df.merge(melanoma_df, on='image_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR FREATURE AND MELANOMA IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame for merged features and melanoma\n",
    "#this data frame shows only data related to melanoma \n",
    "\n",
    "merge_feature_melanoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of data frame\n",
    "merge_feature_melanoma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR FEATURE AND NO DIAGNOSIS IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_feature_non_malignant_df = file_features_df.merge(non_malignant_df, on='image_id', how='right')\n",
    "merge_feature_non_malignant_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyiqoP1MEaKZ"
   },
   "source": [
    "# Explore an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "nWaVMWpawvjr",
    "outputId": "5b0fbd89-20e6-4d11-c8cd-a897dfb54a7a"
   },
   "outputs": [],
   "source": [
    "# Load an image and display it\n",
    "\n",
    "im = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for basic properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Properties of an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_img(image):\n",
    "    print('Type of the image : ' , type(image)) \n",
    "    print('Shape of the image : {}'.format(image.shape)) \n",
    "    print('Image Hight {}'.format(image.shape[0])) \n",
    "    print('Image Width {}'.format(image.shape[1])) \n",
    "    print('Dimension of Image {}'.format(image.ndim)) #three layers: Red, Green, Blue\n",
    "\n",
    "prob_img(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_max_min(image):\n",
    "    print('Image size {}'.format(image.size)) \n",
    "    print('Maximum RGB value in this image {}'.format(image.max())) \n",
    "    print('Minimum RGB value in this image {}'.format(image.min()))\n",
    "\n",
    "RGB_max_min(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols=3, figsize=(15,5))  \n",
    "for c, ax in zip(range(3), ax):     \n",
    "     # create zero matrix        \n",
    "     split_img = np.zeros(im.shape, dtype=\"uint8\") \n",
    "     # 'dtype' by default: 'numpy.float64'  # assing each channel      \n",
    "     split_img[ :, :, c] = im[ :, :, c] # display each channel     \n",
    "     ax.imshow(split_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erosion\n",
    "\n",
    "_All the pixels near boundary will be discarded depending upon the size of kernel. Useful for removing small white noises_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/example_image/ISIC_0012099.jpg',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "plt.imshow(erosion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation\n",
    "\n",
    "_Opposite of erosion. Increases the white region in the image after erosion removes the white noises, as it also skrinks our objects. Thus, we dilate it. Also useful in joining broken parts of an object together_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(img, kernel, iterations = 1)\n",
    "plt.imshow(dilation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening\n",
    "\n",
    "_Also known as erosion followed by dilation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "plt.imshow(opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "_Reverse of Opening. This, dilation followed by erosion. Useful in closing small holes inside the foreground objects or small black points of the object_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "plt.imshow(closing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Gradient\n",
    "\n",
    "_The difference between dilation and erosion of an image. The result will look like the outline of the object_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "plt.imshow(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StEIy91ByKqa",
    "outputId": "1391d60e-1ad1-4139-9ce6-4eb8db494b6d"
   },
   "outputs": [],
   "source": [
    "#A color image is a array with 3 dimensions (x, y, R-G-B color channels) of integers\n",
    "\n",
    "print(im.shape)\n",
    "print(im.dtype)\n",
    "\n",
    "#Other packages might wrap the image in a different class - you are allowed to use those if you want\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-dimension array of the data. \n",
    "#All of the data is the image: \n",
    "# each matrix block is a row of data, and each element within that is the pixel values in RGB-A (Red Green Blue Alpha)\n",
    "\n",
    "print(np.array(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "LvjH7_r6yyXs",
    "outputId": "762b2672-1942-46ca-8f8c-ce5e5d02f135"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get a single RGB value from the blue circle (marker used by dermatologist)\n",
    "print(im[1500,2000,:])\n",
    "\n",
    "# Show only the red channel\n",
    "plt.imshow(im[:,:,0], cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "NaFP1V3c0ezk",
    "outputId": "d309234a-2eca-4099-8f8b-9f6b70cfd122"
   },
   "outputs": [],
   "source": [
    "# Display only a part of the image\n",
    "\n",
    "im_part = im[60:120,130:220,:]\n",
    "plt.imshow(im_part)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "-YIwdyVGE_uA",
    "outputId": "52d76974-08d7-422b-d0bc-36e880774920"
   },
   "outputs": [],
   "source": [
    "# Modify the image by setting some pixels to black\n",
    "\n",
    "im_copy = im_part.copy()\n",
    "\n",
    "\n",
    "im_copy[0:10,0:10,:] = np.tile(0, [10, 10, 3])\n",
    "plt.imshow(im_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgyeEdZ40eMe"
   },
   "source": [
    "# Explore the segmentation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "294fxuQW1Lkl",
    "outputId": "49c606b2-3b05-42f0-fd0c-e92794cae9e3"
   },
   "outputs": [],
   "source": [
    "# Load the mask and display it\n",
    "\n",
    "mask = plt.imread('../data/example_segmentation/ISIC_0012099_segmentation.png')\n",
    "plt.imshow(mask, cmap='gray')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "Df3dV2UzsM4u",
    "outputId": "c357ffee-09c4-40f6-b262-a54a45cf1558"
   },
   "outputs": [],
   "source": [
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "EGheRlVIvVdS",
    "outputId": "877e38f1-beef-4d2b-be86-768d9d3bf602"
   },
   "outputs": [],
   "source": [
    "# Show the images overlayed, for this we can use PIL \n",
    "\n",
    "#!pip install pillow \n",
    "from PIL import Image \n",
    "\n",
    "# Load images as Image objects  \n",
    "img1 = Image.open('../data/example_image/ISIC_0012099.jpg') \n",
    "img2 = Image.open('../data/example_segmentation/ISIC_0012099_segmentation.png') \n",
    "  \n",
    "# Overlay - more options such as transparency should be available here  \n",
    "img2.paste(img1, (0,0), mask = img2) \n",
    "  \n",
    "# Display \n",
    "img2.show()  # This doesn't actually display an image in Google Colab :(\n",
    "plt.imshow(img2, cmap='gray')\n",
    "\n",
    "\n",
    "# Note that this is a single channel image\n",
    "print(img2.size)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "wahUSCWGxD7L",
    "outputId": "698df7ff-13d6-4f38-bbfe-5f2dc31e8e6a"
   },
   "outputs": [],
   "source": [
    "# Alternative: replace the non-lesion pixels\n",
    "\n",
    "img1 = im.copy()\n",
    "img1[mask==0] = 0\n",
    "  \n",
    "# Display \n",
    "plt.imshow(img1)\n",
    "\n",
    "# You can use any package you prefer, but beware you might need to convert between formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "m9OpMIoj9Noq",
    "outputId": "af666cfc-87f3-47e2-dd9e-6a45f6902d53"
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "img1 = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "gray = rgb2gray(img1)\n",
    "\n",
    "plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "SKtfGx8z-hxn",
    "outputId": "4bdf3789-969d-4e10-fdb0-4bfa164e08d9"
   },
   "outputs": [],
   "source": [
    "#plt.hist(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "tiZb_ynW_GUF",
    "outputId": "1a2476d6-eb18-4904-b820-d46f47938fc9"
   },
   "outputs": [],
   "source": [
    "img2 = gray < 120\n",
    "plt.imshow(img2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurements and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "\n",
    "mask=plt.imread('../data/example_segmentation/ISIC_0012099_segmentation.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total size of the image\n",
    "\n",
    "total = mask.shape[0] * mask.shape[1]\n",
    "print(\"total size of the image is \", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of mask only: sum of all pixel values in the mask\n",
    "\n",
    "area = np.sum(mask)\n",
    "print(\"size of area is\", area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as percentage\n",
    "\n",
    "print(area/total*100)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement: width/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_in_col = np.max(np.sum(mask, axis=0))\n",
    "pixels_in_row = np.max(np.sum(mask, axis=1))\n",
    "print(\"Number of pixels in column is, also known as width \\n\",pixels_in_col, '\\n')\n",
    "\n",
    "print(\"Number of pixels in row is, also known as height \\n\",pixels_in_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement: diameter at an angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "rot_im = transform.rotate(mask, 30)\n",
    "plt.imshow(rot_im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find perimeter using morphology\n",
    "\n",
    "_perimeter is the sum of pixels on the border_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "#Structural element, that we will use as a \"brush\" on our mask\n",
    "struct_el = morphology.disk(20)\n",
    "\n",
    "print(struct_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "\n",
    "# Show side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 5))\n",
    "axes[0].imshow(mask, cmap='gray')\n",
    "axes[1].imshow(mask_eroded, cmap='gray')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Verify it's smaller\n",
    "print(area)\n",
    "print(np.sum(mask_eroded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the two masks from each other to get the border/perimeter\n",
    "\n",
    "image_perimeter = mask - mask_eroded\n",
    "\n",
    "plt.imshow(image_perimeter, cmap='gray') #The perimeter is very thin so it might be difficult to see on the screen\n",
    "\n",
    "#What is the length? \n",
    "print('The perimeter or border of the area is', np.sum(image_perimeter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your own mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with color image as grayscale\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "gray = rgb2gray(im)\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of the marker\n",
    "gray2 = gray[0:1400,:]\n",
    "plt.imshow(gray2, cmap='gray')\n",
    "\n",
    "mask2 = mask[0:1500,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at intensities of image\n",
    "#plt.hist(gray2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Threshold\n",
    "mymask = gray2 < 120  #Pixels with lower intensities will be equal to 1 in the mask\n",
    "plt.imshow(mymask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is some noise, we can get rid of it by morphological operators\n",
    "\n",
    "from skimage.morphology import opening\n",
    "\n",
    "# Opening = first EROSION, then DILATION \n",
    "\n",
    "# Erosion will get rid of hairs but also make the lesion smaller. \n",
    "# Dilation will restore the lesion (but not the hairs)\n",
    "\n",
    "struct_el = morphology.disk(5)\n",
    "opened = opening(mask2, struct_el)\n",
    "\n",
    "plt.imshow(opened, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filtering (blur)\n",
    "\n",
    "from skimage import filters\n",
    "\n",
    "blurred = filters.gaussian(mask,sigma=10)\n",
    "\n",
    "plt.imshow(blurred, cmap='gray')\n",
    "\n",
    "#What kind of values are in the image now?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold again\n",
    "\n",
    "mask2 = blurred > 0.5\n",
    "plt.imshow(mask2, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur color image - this could be useful for measuring color (variability)\n",
    "\n",
    "blurred = filters.gaussian(im,sigma=25)\n",
    "\n",
    "plt.imshow(blurred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General purpose features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many examples in https://scikit-image.org/docs/dev/api/skimage.feature.html \n",
    "\n",
    "# Crop image first\n",
    "\n",
    "im2 = im[700:1150,1250:1700,:]\n",
    "mask2 = mask[700:1150,1250:1700]\n",
    "\n",
    "\n",
    "plt.imshow(im2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian features recently available (might need to update version)\n",
    "\n",
    "# Example segmentation for microscopy image: https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_trainable_segmentation.html#sphx-glr-auto-examples-segmentation-plot-trainable-segmentation-py \n",
    "\n",
    "!pip install scikit-image==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from skimage import feature\n",
    "from functools import partial \n",
    "\n",
    "#Extract feature images\n",
    "feat_im = feature.multiscale_basic_features(im2, multichannel=True, intensity=False, edges=False, texture=True)\n",
    "print(feat_im.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feat_im[:,:,3], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We measured X features for every pixel in the image - this is good for segmentation, but not image classification yet\n",
    "\n",
    "# For classification we need to aggregate the outputs for each feature type into one vector\n",
    "\n",
    "feat_vec, bin_edges = np.histogram(feat_im[:,:,8], bins=16)\n",
    "\n",
    "plt.bar(np.arange(0,16), feat_vec)\n",
    "print(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine bins based on intensities instead... \n",
    "# plt.hist(feat_im[:,:,8], bins='auto')     # Very slow for large images\n",
    "\n",
    "flat_im = np.ndarray.flatten(feat_im[:,:,8])\n",
    "flat_mask = np.ndarray.flatten(mask2)\n",
    "\n",
    "# Only pixels inside the mask\n",
    "flat_im = flat_im[flat_mask==1]\n",
    "\n",
    "quantile_bins = np.quantile(flat_im, np.arange(0,1,0.1))\n",
    "\n",
    "# Bins have different widths\n",
    "print(quantile_bins)\n",
    "\n",
    "#feat_vec, bin_edges = np.histogram(flat_im, bins=quantile_bins)\n",
    "print(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that bins should be the same across images (for a particular feature). \n",
    "\n",
    "# Define bins once on \"representative image\" (how?), then use for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script for the FYP 2021 project 3\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_data = 'data/example_ground_truth.csv'\n",
    "path_image = 'data/example_image'\n",
    "path_mask = 'data/example_segmentation'\n",
    "\n",
    "file_features = 'features/features.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "im_test = cv2.imread('../data/example_image/ISIC_0012099.jpg',1)\n",
    "#plt.imshow(im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = im_test.shape\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the width and height\n",
    "h=2000\n",
    "w=3008\n",
    "# Definig aspect ratio of a resized image\n",
    "ratio = 500.0 / w\n",
    "# Dimensions of a resized image\n",
    "dim = (500, int(h * ratio))\n",
    "# We have obtained a new image that we call resized3\n",
    "resized_2 = cv2.resize(im_test, dim)\n",
    "plt.imshow(resized_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = im_test.shape[:2]\n",
    "# Negative values of tx will shift the image to the left\n",
    "# Positive values will shift the image to the right\n",
    "# Negative values of ty will shift the image up\n",
    "# Positive values will shift the image down\n",
    "M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "translated = cv2.warpAffine(im_test, M, (width, height))\n",
    "plt.imshow(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_test = cv2.imread('../data/example_segmentation/ISIC_0012099_segmentation.png',1)\n",
    "img = cv2.imread('../data/example_image/ISIC_0012099.jpg',1)\n",
    "\n",
    "# Crop image first\n",
    "\n",
    "\n",
    "mask_crop = im_test[700:1150,1250:1700]\n",
    "img_crop = img[700:1150,1250:1700]\n",
    "\n",
    "\n",
    "plt.imshow(img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the image around y-axis (horizontal flipping)\n",
    "flipped_y = cv2.flip(img_crop, 1)\n",
    "plt.imshow(flipped_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the image around x-axis (vertical flipping)\n",
    "flipped_x = cv2.flip(img_crop, 0)\n",
    "plt.imshow(flipped_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the image around both axes\n",
    "flipped_both = cv2.flip(img_crop, -1)\n",
    "plt.imshow(flipped_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def hist_plt(mask):\n",
    "   # hist = plt.hist(mask)\n",
    "   # return hist\n",
    "\n",
    "\n",
    "#hist_orignal_img = hist_plt(original_img)\n",
    "#hist_flip_y = hist_plt(mask_flipped_y)\n",
    "#hist_flip_x = hist_plt(mask_flipped_x)\n",
    "#hist_flip_both = hist_plt(mask_flipped_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cropped version\n",
    "input_img = img_crop #original image\n",
    "mask_img  = mask_crop #segmentation image\n",
    "\n",
    "# select only masked area below\n",
    "masked = input_img.copy()\n",
    "masked[mask_img == 0 ] = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 12))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(input_img, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"Original Imput Image\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(mask_img, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"Segmentation Mask\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(masked, cmap=\"gray\")\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Masked Image\", fontsize=12, c = 'w')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "source": [
    "# TASK 1: ABC FEATURES - ASYMMETRY SHAPE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same images flipped vertically and horizontally \n",
    "\n",
    "original_img = rgb2gray(input_img)\n",
    "mask_flipped_y = rgb2gray(flipped_y)\n",
    "mask_flipped_x = rgb2gray(flipped_x)\n",
    "mask_flipped_both  = rgb2gray(flipped_both)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(8, 10))\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[1].imshow(mask_flipped_y, cmap='gray')\n",
    "axes[2].imshow(mask_flipped_x, cmap='gray')\n",
    "axes[3].imshow(mask_flipped_both, cmap='gray')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold: for customizing our own masks for each image\n",
    "def threshold_mask(mask):\n",
    "    custom_mask = mask < 125 #from plt.hist function\n",
    "    return custom_mask\n",
    "\n",
    "cust_mask_orignal = threshold_mask(original_img)\n",
    "cust_mask_y = threshold_mask(mask_flipped_y)\n",
    "cust_mask_x = threshold_mask(mask_flipped_x)\n",
    "cust_mask_both = threshold_mask(mask_flipped_both)\n",
    "\n",
    "\n",
    "# subplot of same flipped masked image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(8, 10))\n",
    "axes[0].imshow(cust_mask_orignal, cmap='gray')\n",
    "axes[1].imshow(cust_mask_y, cmap='gray')\n",
    "axes[2].imshow(cust_mask_x, cmap='gray')\n",
    "axes[3].imshow(cust_mask_both, cmap='gray')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "source": [
    "## Find center points of each segmentation masked image\n",
    "_ code by Gino Franco Fazzi_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerpoint(mask):\n",
    "    borders = np.where(mask == 1) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((up+down) //2, (left + right) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    return center\n",
    "\n",
    "#print(borders)\n",
    "#print(up, down, left, right)\n",
    "#print(center)\n",
    "\n",
    "center_original = centerpoint(cust_mask_orignal)\n",
    "\n",
    "#center_flip_y = centerpoint(mask_flipped_y)\n",
    "#center_flip_x = centerpoint(mask_flipped_x)\n",
    "#center_flip_both = centerpoint(mask_flipped_both)\n",
    "\n",
    "print('Center point coordinates of masked image is:', center_original)\n",
    "\n",
    "#print('Coordinates for the center:', center_flip_y)\n",
    "#print('Coordinates for the center:', center_flip_x)\n",
    "#print('Coordinates for the center:', center_flip_both)"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Original image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_mask_orignal[:,center_original[0]:]\n",
    "plt.imshow(cust_mask_orignal)"
   ]
  },
  {
   "source": [
    "## Subplot: Left part of center line and right part mirrored over center line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Left part of center line\n",
    "left = cust_mask_orignal[:,0:center_original[0]+1]\n",
    "\n",
    "# right part mirrored over the center line\n",
    "right_mirrored = np.fliplr(cust_mask_orignal)[:,0:center_original[0]+1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 8))\n",
    "ax = axes.flatten()\n",
    "\n",
    "\n",
    "ax[0].imshow(left, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"Left part of center line\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(right_mirrored, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"Right part mirrored over center line\", fontsize=12, c = 'w')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "## Subplot: Right part of center line and left part mirrored over center line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right part of the center line\n",
    "right = cust_mask_orignal[:,center_original[0]:]\n",
    "\n",
    "# Left part mirrored over the center line\n",
    "left_mirrored = np.fliplr(cust_mask_orignal)[:,center_original[0]:]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 8))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(right, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"Right part of center line\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(left_mirrored, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"Left part mirrored over center line\", fontsize=12, c = 'w')\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "## Symmetric area of: \n",
    "\n",
    "_ \n",
    "a) the right and left mirrored part of the center line and \n",
    "b) the left and right mirrored part of the center line \n",
    "_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "def find_right_left_mirrored(right, left_mirrored):\n",
    "    right_left_mirrored = right + left_mirrored\n",
    "    symmetric_area_right = np.count_nonzero(right_left_mirrored)\n",
    "    return right_left_mirrored, symmetric_area_right\n",
    "\n",
    "right_left_mirrored, symmetric_area_right = find_right_left_mirrored(right, left_mirrored)\n",
    "print(\"Symmetric area for right and left mirrored parts: \\n\", symmetric_area_right)\n",
    "\n",
    "# b)\n",
    "def find_left_right_mirrored(left, right_mirrored):\n",
    "    left_right_mirrored = left + right_mirrored\n",
    "    symmetric_area_left = np.count_nonzero(left_right_mirrored)\n",
    "    return left_right_mirrored, symmetric_area_left\n",
    "\n",
    "left_right_mirrored, symmetric_area_left = find_left_right_mirrored(left, right_mirrored)\n",
    "\n",
    "print(\"\\nSymmetric area for left and right mirrored parts: \\n\", symmetric_area_left)\n",
    "\n",
    "\n",
    "print(\"\\nTotal size of image: \\n\", cust_mask_orignal.size)\n"
   ]
  },
  {
   "source": [
    "## Subplots of a) and b): visualization of overlapping and non-overlapping parts of images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_A_featur(left_right_mirrored, right_left_mirrored):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 12))\n",
    "    ax = axes.flatten()\n",
    "\n",
    "    ax[0].imshow(left_right_mirrored)\n",
    "    ax[0].set_axis_off()\n",
    "    ax[0].set_title(\"Symmetry: Left of center\", fontsize=12, c = 'w')\n",
    "\n",
    "    ax[1].imshow(right_left_mirrored)\n",
    "    ax[1].set_axis_off()\n",
    "    ax[1].set_title(\"Symmetry: Right of center \", fontsize=12, c = 'w')\n",
    "\n",
    "    return \n",
    "\n",
    "subplot_asymmetry(left_right_mirrored, right_left_mirrored)\n",
    "# Left part plus the right part - see below\n",
    "# The yellow part of the figure are where the two parts intersect (overlapping)\n",
    "# The green part is where the figures are non-overlapping"
   ]
  },
  {
   "source": [
    "## Size of area: accordingly to center line\n",
    "\n",
    "_We will here look at each part: right, left, right_mirrored and left_mirrored parts of the segmentation mask image, and find size of each part seperately_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of mask only: sum of all pixel values in the mask\n",
    "\n",
    "def size_mask_centerline(right, left, right_mirrored, left_mirrored):\n",
    "    area_right = np.sum(right)\n",
    "    #print(f'Size of masked area left of center line is {area_right: 22d}')\n",
    "\n",
    "    area_left = np.sum(left)\n",
    "    #print(f'Size of masked area left of center line is {area_left: 22d}')\n",
    "\n",
    "    area_right_mirrored = np.sum(right_mirrored)\n",
    "    #print(f'Size of masked area right mirrored over center line is {area_right_mirrored: 10d}')\n",
    "\n",
    "    area_left_mirrored = np.sum(left_mirrored)\n",
    "    #print(f'Size of masked area left mirrored over center line is  {area_left_mirrored: 10d}')\n",
    "    return area_right, area_left, area_right_mirrored, area_left_mirrored\n",
    "    \n",
    "\n",
    "size_mask_values = list(size_mask_centerline(right, left, right_mirrored, left_mirrored))\n",
    "\n",
    "\n",
    "#list of names for the different parts of the center line\n",
    "name_key = ['right', 'left', 'right_mirrored', 'left_mirrored']\n",
    "\n",
    "# dictionary where key is the name of the part and value is an integer of mask size\n",
    "res = {name_key[i]: size_mask_values[i] for i in range(len(name_key))}\n",
    "\n",
    "# display name and value of each part in the mask\n",
    "for key in res.items():\n",
    "    print('\\nSize of masked area over center line is:\\n', key)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FYP project 3 - introduction",
   "provenance": []
  },
  "kernelspec": {
   "name": "python392jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}