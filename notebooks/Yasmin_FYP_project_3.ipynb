{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fQN_SBG0idm"
   },
   "source": [
    "## Get some images and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import data, io, filters\n",
    "from skimage.morphology import opening\n",
    "from skimage import filters\n",
    "from skimage import transform\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "from skimage import morphology\n"
   ]
  },
  {
   "source": [
    "# Imaging Processing: \n",
    "## Loading Images, Grayscaling, Customizing Masks from Images, Cropping all Images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_data = '../data/example_ground_truth.csv'\n",
    "path_image = '../data/example_image'\n",
    "path_mask = '../data/example_segmentation'\n",
    "\n",
    "file_features = '../features/features.csv'\n",
    "\n",
    "df = pd.read_csv(file_data)\n",
    "\n",
    "\n",
    "image_id = list(df['image_id'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_list = [] \n",
    "custom_seg_list = []\n",
    "\n",
    "image_colour = 45\n",
    "\n",
    "# STEP 1: Read and Grayscale images\n",
    "for image_colour in range(45,50):\n",
    "    # reads the image\n",
    "    img = cv2.imread(path_image + os.sep + image_id[image_colour] + '.jpg')\n",
    "    image_colour +=1\n",
    "    # calls the function for grayscaling images\n",
    "    gray_image = rgb2gray(img)\n",
    "\n",
    "    thresh = threshold_otsu(gray_image)\n",
    "    binary = (gray_image < thresh)\n",
    "\n",
    "    # appends grayscaled images to list\n",
    "    image_list.append(binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Customize masks for all gray images\n",
    "# take all gray images, turn them into binary images by threshold\n",
    "# append new segmentation images into list\n",
    "for image_gray in range(5):\n",
    "    \n",
    "    # Erosion will get rid of hairs but also make the lesion smaller. \n",
    "    # Dilation will restore the lesion (but not the hairs)\n",
    "\n",
    "    # There is some noise, we can get rid of it by morphological operators\n",
    "    #Structural element, that we will use as a \"brush\" on our mask\n",
    "    struct_el = morphology.disk(20)\n",
    "\n",
    "    #mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "\n",
    "    opened = opening(image_list[image_gray],struct_el)\n",
    "    img_crop = crop_image(opened)\n",
    " \n",
    "    # Gaussian filtering (blur)\n",
    "    blurred_mask = filters.gaussian(img_crop,sigma=5) \n",
    "\n",
    "    # Rotate mask\n",
    "    custom_seg_list.append(blurred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img,tol=0):\n",
    "    # img is 2D image data\n",
    "    # tol  is tolerance\n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Save all customized segmentation mask by image_id \n",
    "\n",
    "path_processed = '../data/processed'\n",
    "idx = 45\n",
    "for img in range(5):\n",
    "    #img_crop = crop_image(custom_seg_list[img])\n",
    "    plt.imshow(custom_seg_list[img], cmap='gray')\n",
    "    #plt.imshow(custom_seg_list[img], cmap=\"gray\")\n",
    "    plt.savefig(path_processed + os.sep + image_id[idx] + \"_customized.png\")\n",
    "    idx +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold: for customizing our own masks for each image\n",
    "def threshold_mask(mask):\n",
    "    custom_mask = mask < 120 #from plt.hist function\n",
    "    return custom_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_seg_list = np.array(custom_seg_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING IN FILE: EXAMPLE_GROUND_TRUTH.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read file\n",
    "file_input = pd.read_csv(\"../data/example_ground_truth.csv\")\n",
    "file_input.shape\n",
    "\n",
    "#150 images in total\n",
    "#3 columns: image_id, melanoma, keratosis\n",
    "\n",
    "file_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FRAME FOR IMAGES WITH NO DIAGNOSIS, MEANING MELANOMA AND KERATOSIS == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame for images with no diagnosis\n",
    "non_malignant_df = file_input.loc[(file_input['melanoma'] == 0.0) & (file_input[\"seborrheic_keratosis\"] == 0.0)]\n",
    "non_malignant_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR IMAGES WITH MELANOMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out all images that are not melanoma\n",
    "melanoma = file_input[file_input[\"melanoma\"] == 1.0]\n",
    "\n",
    "#remove column for keratosis\n",
    "melanoma_df = melanoma.drop([\"seborrheic_keratosis\"], axis = 1)\n",
    "#number of images left\n",
    "melanoma.shape\n",
    "melanoma_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING IN FILE FOR FEATURES.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file features\n",
    "file_features_df = pd.read_csv(\"../features/features.csv\")\n",
    "# file_features_df.shape\n",
    "# 150 rows, 3 columns\n",
    "\n",
    "#data frame for features\n",
    "file_features_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data frame for features with data frame for melanoma to filter out non-related images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column 'id' to 'image_id'\n",
    "file_features_df.rename(columns={'id': 'image_id'}, inplace=True)\n",
    "\n",
    "#merge data frame for file_features_df with melanoma by column 'image_id'\n",
    "merge_feature_melanoma = file_features_df.merge(melanoma_df, on='image_id', how='right')\n",
    "\n",
    "#data frame for merged features and melanoma\n",
    "#this data frame shows only data related to melanoma \n",
    "\n",
    "merge_feature_melanoma \n",
    "\n",
    "# size of data frame\n",
    "# merge_feature_melanoma.shape\n",
    "# (30, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR FEATURE AND NO DIAGNOSIS IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_feature_non_malignant_df = file_features_df.merge(non_malignant_df, on='image_id', how='right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for basic properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erosion\n",
    "\n",
    "_All the pixels near boundary will be discarded depending upon the size of kernel. Useful for removing small white noises_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/example_image/ISIC_0012099.jpg',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation\n",
    "\n",
    "_Opposite of erosion. Increases the white region in the image after erosion removes the white noises, as it also skrinks our objects. Thus, we dilate it. Also useful in joining broken parts of an object together_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(img, kernel, iterations = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening\n",
    "\n",
    "_Also known as erosion followed by dilation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "_Reverse of Opening. This, dilation followed by erosion. Useful in closing small holes inside the foreground objects or small black points of the object_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Gradient\n",
    "\n",
    "_The difference between dilation and erosion of an image. The result will look like the outline of the object_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(12, 10))\n",
    "axes[0].imshow(erosion)\n",
    "axes[1].imshow(dilation)\n",
    "axes[2].imshow(opening)\n",
    "axes[3].imshow(closing)\n",
    "axes[4].imshow(gradient)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgyeEdZ40eMe"
   },
   "source": [
    "# Explore the segmentation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "EGheRlVIvVdS",
    "outputId": "877e38f1-beef-4d2b-be86-768d9d3bf602"
   },
   "outputs": [],
   "source": [
    "# Show the images overlayed, for this we can use PIL \n",
    "#!pip install pillow \n",
    "from PIL import Image \n",
    "\n",
    "# Load images as Image objects  \n",
    "img1 = Image.open('../data/example_image/ISIC_0001769.jpg') \n",
    "img2 = Image.open('../data/processed/ISIC_0001769_customized.png') \n",
    "\n",
    "# Overlay - more options such as transparency should be available here  \n",
    "img2.paste(img1, (0,0), mask = img2) \n",
    "  \n",
    "# Display \n",
    "img2.show()  # This doesn't actually display an image in Google Colab :(\n",
    "plt.imshow(img2, cmap='gray')\n",
    "\n",
    "\n",
    "# Note that this is a single channel image\n",
    "print(img2)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "m9OpMIoj9Noq",
    "outputId": "af666cfc-87f3-47e2-dd9e-6a45f6902d53"
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "img1 = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "gray = rgb2gray(img1)\n",
    "\n",
    "# final_binary_mask\n",
    "final_binary_mask = (gray < 120)\n",
    "#plt.savefig()\n",
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].imshow(gray)\n",
    "axes[1].imshow(final_binary_mask, cmap='gray')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert array back to integers from booleans\n",
    "final_binary_mask = final_binary_mask.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurements and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "\n",
    "mask=plt.imread('../data/example_segmentation/ISIC_0012099_segmentation.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total size of the image\n",
    "\n",
    "total = mask.shape[0] * mask.shape[1]\n",
    "print(\"total size of the image is \", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of mask only: sum of all pixel values in the mask\n",
    "\n",
    "area = np.sum(mask)\n",
    "print(\"size of area is\", area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as percentage\n",
    "\n",
    "print(area/total*100)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement: width/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pixels_in_col = np.max(np.sum(mask, axis=0))\n",
    "pixels_in_row = np.max(np.sum(mask, axis=1))\n",
    "print(\"Number of pixels in column is, also known as width \\n\",pixels_in_col, '\\n')\n",
    "\n",
    "print(\"Number of pixels in row is, also known as height \\n\",pixels_in_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement: diameter at an angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].imshow(mask)\n",
    "axes[1].imshow(rot_im, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "# Crop and center segnmentation mask in the middle of image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mask = cv2.imread('../data/example_segmentation/ISIC_0012099_segmentation.png', 0)\n",
    "\n",
    "\n",
    "height, width = mask.shape\n",
    "x,y,w,h = cv2.boundingRect(mask)\n",
    "\n",
    "# Create new blank image and shift ROI to new coordinates\n",
    "image_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "ROI = mask[y:y+h, x:x+w]\n",
    "x = width//2 - ROI.shape[0]//2 \n",
    "y = height//2 - ROI.shape[1]//2 \n",
    "image_mask[y:y+h, x:x+w] = ROI\n",
    "\n",
    "# cropped version of segmentation mask\n",
    "cv2.imshow('ROI', ROI)\n",
    "\n",
    "# original version of segmentation mask\n",
    "cv2.imshow('mask', image_mask)\n",
    "\n",
    "\n",
    "\n",
    "# press 0 to stop the processing\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "src1 = cv2.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "mask = cv2.imread('../data/example_segmentation/ISIC_0012099_segmentation.png', 0)\n",
    "\n",
    "#change mask to a 3 channel image \n",
    "src1_mask=cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "mask_out=cv2.subtract(src1_mask,src1)\n",
    "mask_out=cv2.subtract(src1_mask,mask_out)\n",
    "\n",
    "height, width = mask.shape\n",
    "x,y,w,h = cv2.boundingRect(mask)\n",
    "\n",
    "# Create new blank image and shift ROI to new coordinates\n",
    "image_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "mask_out = mask[y:y+h, x:x+w]\n",
    "x = width//2 - mask_out.shape[0]//2 \n",
    "y = height//2 - mask_out.shape[1]//2 \n",
    "image_mask[y:y+h, x:x+w] = mask_out\n",
    "\n",
    "cv2.imshow('original image', src1)\n",
    "cv2.imshow('greyscale mask', mask)\n",
    "cv2.imshow('cropped coloured mask', image_mask)\n",
    "cv2.imshow('colored masked image', mask_out)\n",
    "#cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12, 10))\n",
    "axes[0].imshow(src1)\n",
    "axes[1].imshow(image_mask, cmap=\"gray\")\n",
    "axes[2].imshow(mask_out)\n",
    "axes[3].imshow(mask)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 5))\n",
    "axes[0].imshow(mask, cmap='gray')\n",
    "axes[1].imshow(ROI, cmap='gray')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find perimeter using morphology\n",
    "\n",
    "_perimeter is the sum of pixels on the border_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "#Structural element, that we will use as a \"brush\" on our mask\n",
    "struct_el = morphology.disk(20)\n",
    "\n",
    "print(struct_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "#Structural element, that we will use as a \"brush\" on our mask\n",
    "struct_el = morphology.disk(20)\n",
    "\n",
    "mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "\n",
    "# Show side by side\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 5))\n",
    "axes[0].imshow(mask, cmap='gray')\n",
    "axes[1].imshow(ROI, cmap='gray')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Verify it's smaller\n",
    "print(\"Area of mask:\", area)\n",
    "print(\"Mask Eroded: \", np.sum(mask_eroded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the two masks from each other to get the border/perimeter\n",
    "\n",
    "image_perimeter = mask - mask_eroded\n",
    "\n",
    "plt.imshow(image_perimeter, cmap='gray') #The perimeter is very thin so it might be difficult to see on the screen\n",
    "\n",
    "#What is the length? \n",
    "print('The perimeter or border of the area is', np.sum(image_perimeter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your own mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with color image as grayscale\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "gray = rgb2gray(im)\n",
    "\n",
    "\n",
    "# Let's get rid of the marker\n",
    "gray2 = gray[0:1400,:]\n",
    "mask2 = mask[0:1500,:]\n",
    "\n",
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 8))\n",
    "axes[0].imshow(gray, cmap='gray')\n",
    "axes[1].imshow(gray2, cmap='gray')\n",
    "axes[2].imshow(mask2, cmap='gray')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at intensities of image\n",
    "#plt.hist(gray2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "#mymask = gray2 < 120  #Pixels with lower intensities will be equal to 1 in the mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filtering (blur)\n",
    "\n",
    "from skimage import filters\n",
    "\n",
    "blurred_ROI = filters.gaussian(ROI,sigma=8)\n",
    "blurred_mask = filters.gaussian(mask,sigma=10)\n",
    "\n",
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].imshow(blurred_mask, cmap='gray')\n",
    "axes[1].imshow(blurred_ROI, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold again\n",
    "\n",
    "ROI_2 = blurred_ROI > 0.5\n",
    "mask_2 = blurred_mask > 0.5\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].imshow(mask_2, cmap='gray')\n",
    "axes[1].imshow(ROI_2, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur color image - this could be useful for measuring color (variability)\n",
    "\n",
    "blurred_mask_color = filters.gaussian(mask,sigma=25)\n",
    "blurred_ROI_colour = filters.gaussian(ROI,sigma=25)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].imshow(blurred_mask_color)\n",
    "axes[1].imshow(blurred_ROI_colour)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General purpose features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many examples in https://scikit-image.org/docs/dev/api/skimage.feature.html \n",
    "\n",
    "# Crop image first manually\n",
    "im2 = im[700:1150,1250:1700,:]\n",
    "mask2 = mask[700:1150,1250:1700]\n",
    "\n",
    "plt.imshow(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian features recently available (might need to update version)\n",
    "\n",
    "# Example segmentation for microscopy image: https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_trainable_segmentation.html#sphx-glr-auto-examples-segmentation-plot-trainable-segmentation-py \n",
    "\n",
    "#!pip install scikit-image==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage import feature\n",
    "from functools import partial \n",
    "\n",
    "#Extract feature images\n",
    "feat_im = feature.multiscale_basic_features(im2, multichannel=True, intensity=False, edges=False, texture=True)\n",
    "print(feat_im.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feat_im[:,:,3], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We measured X features for every pixel in the image - this is good for segmentation, but not image classification yet\n",
    "\n",
    "# For classification we need to aggregate the outputs for each feature type into one vector\n",
    "\n",
    "feat_vec, bin_edges = np.histogram(feat_im[:,:,8], bins=16)\n",
    "\n",
    "plt.bar(np.arange(0,16), feat_vec)\n",
    "print(feat_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the image around y-axis (horizontal flipping)\n",
    "flipped_y = cv2.flip(im2, 1)\n",
    "\n",
    "# Flipping the image around x-axis (vertical flipping)\n",
    "flipped_x = cv2.flip(im2, 0)\n",
    "\n",
    "# Flipping the image around both axes\n",
    "flipped_both = cv2.flip(im2, -1)\n",
    "\n",
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8, 4))\n",
    "axes[0].imshow(flipped_y)\n",
    "axes[1].imshow(flipped_x)\n",
    "axes[2].imshow(flipped_both)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropped version\n",
    "input_img = im2 #original image\n",
    "mask_img  = mask2 #segmentation image\n",
    "\n",
    "# select only masked area below\n",
    "masked = input_img.copy()\n",
    "masked[mask_img == 0 ] = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 12))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(input_img, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"Original Imput Image\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(mask_img, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"Segmentation Mask\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(masked, cmap=\"gray\")\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Masked Image\", fontsize=12, c = 'w')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "source": [
    "# TASK 1: ABC FEATURES - ASYMMETRY SHAPE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same images flipped vertically and horizontally \n",
    "\n",
    "original_img = rgb2gray(input_img)\n",
    "mask_flipped_y = rgb2gray(flipped_y)\n",
    "mask_flipped_x = rgb2gray(flipped_x)\n",
    "mask_flipped_both  = rgb2gray(flipped_both)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(8, 10))\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[1].imshow(mask_flipped_y, cmap='gray')\n",
    "axes[2].imshow(mask_flipped_x, cmap='gray')\n",
    "axes[3].imshow(mask_flipped_both, cmap='gray')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Idea for implementing crop function for saved customized segmentation masks of all images\n",
    "\n",
    "# = 'data/example_ground_truth.csv'\n",
    "#df = pd.read_csv(file_data)\n",
    "\n",
    "# path for all images\n",
    "#path_image = 'data/example_image'\n",
    "\n",
    "# insert all image_ids into list\n",
    "#image_id = list(df['image_id'])\n",
    "\n",
    "# read all image files\n",
    "#file_img = cv2.imread(path_image + os.sep + image_id[i] + '.jpg', 0)\n",
    "\n",
    "\n",
    "\n",
    "# customize masks by original image\n",
    "    # turn image into grayscale def rgb2gray\n",
    "        # gray_X = rgb2gray(X)\n",
    "    # change variable into array int\n",
    "    # call function for threshold_mask \n",
    "    # save all new images under customized segmentation .png\n",
    "\n",
    "# crop all images by customized masks \n",
    "    # read all customized segmentation masks\n",
    "    # read all images\n",
    "    # crop by ROI and image_mask\n",
    "    # save alle images for further analysis\n",
    "\n",
    "# rotate all customized segmentation masks for asymmetric analysis\n",
    "    # purpose: to prevent errors during overlapping\n",
    "    # if image is cylinder but not angled vertically/horizontally 90 degrees by center point, \n",
    "    # there will be non-overlapping bits even though this form is symmetric. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_X_mask = threshold_mask(gray_X)\n",
    "gray_X_mask.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# press 0 to stop the processing\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold: for customizing our own masks for each image\n",
    "def threshold_mask(mask):\n",
    "    custom_mask = mask < 120 #from plt.hist function\n",
    "    return custom_mask\n",
    "\n",
    "cust_mask_orignal = threshold_mask(original_img)\n",
    "cust_mask_y = threshold_mask(mask_flipped_y)\n",
    "cust_mask_x = threshold_mask(mask_flipped_x)\n",
    "cust_mask_both = threshold_mask(mask_flipped_both)\n",
    "\n",
    "\n",
    "# subplot of same flipped masked image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(8, 10))\n",
    "axes[0].imshow(cust_mask_orignal, cmap='gray')\n",
    "axes[1].imshow(cust_mask_y, cmap='gray')\n",
    "axes[2].imshow(cust_mask_x, cmap='gray')\n",
    "axes[3].imshow(cust_mask_both, cmap='gray')\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set customized mask to float\n",
    "cust_mask_orignal.astype(float)\n"
   ]
  },
  {
   "source": [
    "## Find center points of each segmentation masked image\n",
    "_ code by Gino Franco Fazzi_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def centerpoint(mask):\n",
    "    borders = np.where(mask != 0) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((up+down) //2, (left + right) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    return center\n",
    "\n",
    "#print(borders)\n",
    "#print(up, down, left, right)\n",
    "#print(center)\n",
    "\n",
    "center_original_img = centerpoint(input_img)\n",
    "center_seg_mask = centerpoint(mask_img)\n",
    "center_cust_mask = centerpoint(cust_mask_orignal)\n",
    "\n",
    "print('Center point coordinates of masked image is:', center_original_img)\n",
    "print('Center point coordinates of masked image is:', center_seg_mask)\n",
    "print('Center point coordinates of masked image is:', center_cust_mask)\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Original image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img[:,center_original_img[0]:]\n",
    "mask_img[:,center_seg_mask[0]:]\n",
    "cust_mask_orignal[:,center_cust_mask[0]:]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 8))\n",
    "axes[0].imshow(original_img, cmap=\"gray\")\n",
    "axes[0].set_title(\"1) Grayscaled Original Image\", fontsize=12, c = 'w')\n",
    "\n",
    "axes[1].imshow(mask_img, cmap='gray')\n",
    "axes[1].set_title(\"2) Segmentation Mask Image\", fontsize=12, c = 'w')\n",
    "\n",
    "axes[2].imshow(cust_mask_orignal, cmap='gray')\n",
    "axes[2].set_title(\"3: Customized Mask Image\", fontsize=12, c = 'w')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "source": [
    "## Horizontal Asymmetry Analysis for Segmentation Mask"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Left part of center line\n",
    "left_horizontal_img = mask_img[:,0:center_seg_mask[0]+1]\n",
    "\n",
    "# right part mirrored over the center line\n",
    "right_flipped_img = np.fliplr(mask_img)[:,0:center_seg_mask[0]+1]\n",
    "\n",
    "overlapping_left_horizontal = cv2.addWeighted(left_horizontal_img, 0.5, right_flipped_img, 0.5, 1.0)\n",
    "#plt.imshow(overlapping_left_horizontal)\n",
    "\n",
    "def horizontal_asymmetry_left_plot(left_horizontal_image, right_flipped_image, left_overlapping_images):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(6, 8))\n",
    "\n",
    "    ax = axes.flatten()\n",
    "    ax[0].imshow(left_horizontal_image, cmap=\"gray\")\n",
    "    ax[0].set_axis_off()\n",
    "    ax[0].set_title(\"A: Left Horizontal Part of Image\", fontsize=12, c = 'w')\n",
    "\n",
    "    ax[1].imshow(right_flipped_image, cmap=\"gray\")\n",
    "    ax[1].set_axis_off()\n",
    "    ax[1].set_title(\"B: Flipped Horizontal Part of Image\", fontsize=12, c = 'w')\n",
    "\n",
    "    ax[2].imshow(left_overlapping_images, cmap=\"gray\")\n",
    "    ax[2].set_axis_off()\n",
    "    ax[2].set_title(\"Intersection of A and B:\\nGray area are non-overlaps\", fontsize=12, c = 'w')\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=2.0, \n",
    "                        top=0.9, \n",
    "                        wspace=0.4, \n",
    "                        hspace=0.4)\n",
    "    \n",
    "\n",
    "horizontal_asymmetry_left_plot(left_horizontal_img, right_flipped_img, overlapping_left_horizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right part of the center line\n",
    "right_horizontal_img = mask_img[:,center_seg_mask[0]:]\n",
    "\n",
    "# Left part mirrored over the center line\n",
    "left_flipped_img = np.fliplr(mask_img)[:,center_seg_mask[0]:]\n",
    "\n",
    "overlapping_right_horizontal = cv2.addWeighted(right_horizontal_img, 0.5, left_flipped_img, 0.5, 1.0)\n",
    "#plt.imshow(overlapping_left_horizontal)\n",
    "\n",
    "def horizontal_asymmetry_right_plot(right_image, left_flipped_image, right_overlapping_images):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(6, 8))\n",
    "    ax = axes.flatten()\n",
    "\n",
    "    ax[0].imshow(right_image, cmap=\"gray\")\n",
    "    ax[0].set_axis_off()\n",
    "    ax[0].set_title(\"C: Right Horizontal Part of Image\", fontsize=12, c = 'w')\n",
    "\n",
    "    ax[1].imshow(left_flipped_image, cmap=\"gray\")\n",
    "    ax[1].set_axis_off()\n",
    "    ax[1].set_title(\"D: Left Flipped Part of Image\", fontsize=12, c = 'w')\n",
    "\n",
    "    ax[2].imshow(right_overlapping_images, cmap=\"gray\")\n",
    "    ax[2].set_axis_off()\n",
    "    ax[2].set_title(\"Intersection of C and D:\\nGray area are non-overlaps\", fontsize=12, c = 'w')\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=2.0, \n",
    "                        top=0.9, \n",
    "                        wspace=0.4, \n",
    "                        hspace=0.4)\n",
    "    #plt.show()\n",
    "\n",
    "horizontal_asymmetry_right_plot(right_horizontal_img, left_flipped_img,overlapping_right_horizontal)\n",
    "\n",
    "# Left part plus the right part - see below\n",
    "# The white part of the figure are where the two parts intersect (overlapping)\n",
    "# The gray part is where the figures are non-overlapping"
   ]
  },
  {
   "source": [
    "# Horizontal Asymmetry Analysis of customized mask"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left part of center line\n",
    "left_horizontal_cust = cust_mask_orignal[:,0:center_cust_mask[0]+1].astype(float)\n",
    "\n",
    "# right part mirrored over the center line\n",
    "right_flipped_cust = np.fliplr(cust_mask_orignal)[:,0:center_cust_mask[0]+1].astype(float)\n",
    "\n",
    "overlap_left_cust = cv2.addWeighted(left_horizontal_cust, 0.5, right_flipped_cust, 0.5, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_asymmetry_left_plot(left_horizontal_cust, right_flipped_cust, overlap_left_cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right part of the center line\n",
    "right_horizontal_cust = cust_mask_orignal[:,center_cust_mask[0]:].astype(float)\n",
    "\n",
    "# Left part mirrored over the center line\n",
    "left_flipped_cust = np.fliplr(cust_mask_orignal)[:,center_cust_mask[0]:].astype(float)\n",
    "\n",
    "overlapping_right_horizontal_cust = cv2.addWeighted(right_horizontal_cust, 0.5, left_flipped_cust, 0.5, 1.0)\n",
    "\n",
    "horizontal_asymmetry_right_plot(right_horizontal_cust, left_flipped_cust, overlapping_right_horizontal_cust)"
   ]
  },
  {
   "source": [
    "## Calculation of symmetric area and asymmetric area of: \n",
    "\n",
    "We will calculate symmetric values by unionizing the two halves images, and asymmetric values by intersecting the two halves.\n",
    "\n",
    "_ \n",
    "a) horizontal right part and leff flipped part of image and \n",
    "b) horizontal left and right flipped part of image\n",
    "_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplots_asymmetry(image, flipped_image):\n",
    "    img_bwa = cv2.bitwise_and(image,flipped_image)\n",
    "    img_bwo = cv2.bitwise_or(image,flipped_image)\n",
    "    img_bwx = cv2.bitwise_xor(image,flipped_image)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8, 4))\n",
    "    axes[0].imshow(img_bwa, cmap='gray')\n",
    "    axes[0].set_title(\"Intersection of Images \", fontsize=12, c = 'w')\n",
    "\n",
    "    axes[1].imshow(img_bwo, cmap='gray')\n",
    "    axes[1].set_title(\"Union of Images\", fontsize=12, c = 'w')\n",
    "\n",
    "    axes[2].imshow(img_bwx, cmap='gray')\n",
    "    axes[2].set_title(\"Symmetric Difference of Images\", fontsize=12, c = 'w')\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=1.0, \n",
    "                        top=0.9, \n",
    "                        wspace=0.4, \n",
    "                        hspace=0.4)\n",
    "\n",
    "    #fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "def right_horizontal_symmetry(right_horizontal_image, left_flipped_image):\n",
    "    img_bwa = cv2.bitwise_and(right_horizontal_image,left_flipped_image)\n",
    "    img_bwo = cv2.bitwise_or(right_horizontal_image,left_flipped_image)\n",
    "    img_bwx = cv2.bitwise_xor(right_horizontal_image,left_flipped_image)\n",
    "    symmetry_right = np.count_nonzero(img_bwa)\n",
    "    total_size_right = np.count_nonzero(img_bwo)\n",
    "    asymmetry_right = np.count_nonzero(img_bwx)\n",
    "    return symmetry_right, total_size_right, asymmetry_right\n",
    "\n",
    "intersection_right_horizontal, union_right, symmetric_diff_right_horizontal = right_horizontal_symmetry(right_horizontal_img, left_flipped_img)\n",
    "\n",
    "\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nRight Horizontal Part\")\n",
    "print(\"___\" *15)\n",
    "\n",
    "print(\"\\nIntersection of Image A and B: \\n\", intersection_right_horizontal)\n",
    "print(\"\\nUnion of Image A and B: \\n\", union_right)\n",
    "print(\"\\nSymmetric Differene of Image A and B: \\n\", symmetric_diff_right_horizontal)\n",
    "\n",
    "\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nSubplot of Right Horizontal Part\")\n",
    "print(\"___\" *15)\n",
    "print(\"\")\n",
    "subplots_asymmetry(right_horizontal_img, left_flipped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "def left_horizontal_symmetry(left_horizontal_image, right_flipped_image):\n",
    "    img_bwa = cv2.bitwise_and(left_horizontal_image,right_flipped_image)\n",
    "    img_bwo = cv2.bitwise_or(left_horizontal_image,right_flipped_image)\n",
    "    img_bwx = cv2.bitwise_xor(left_horizontal_image,right_flipped_image)\n",
    "    symmetry_left = np.count_nonzero(img_bwa)\n",
    "    total_size_left = np.count_nonzero(img_bwo)\n",
    "    asymmetry_left = np.count_nonzero(img_bwx)\n",
    "    return symmetry_left, total_size_left, asymmetry_left\n",
    "\n",
    "intersection_left_horizontal, union_left, symmetric_diff_left_horizontal = left_horizontal_symmetry(left_horizontal_img, right_flipped_img)\n",
    "\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nLeft Horizontal Part\")\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nIntersetion of Image D and C:\\n\", intersection_left_horizontal)\n",
    "print(\"\\nUnion of Image D and C:\\n\", union_left)\n",
    "print(\"\\nSymmetric Difference of Image D and C:\\n\", symmetric_diff_left_horizontal)\n",
    "\n",
    "\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nSubplot of Left Horizontal Part\")\n",
    "print(\"___\" *15)\n",
    "print(\"\")\n",
    "subplots_asymmetry(left_horizontal_img, right_flipped_img)\n"
   ]
  },
  {
   "source": [
    "## Calculation of symmetric area and asymmetric area of _*customized mask*_: \n",
    "\n",
    "We will calculate symmetric values by unionizing the two halves images, and asymmetric values by intersecting the two halves.\n",
    "\n",
    "_ \n",
    "a) horizontal right part and leff flipped part of image and \n",
    "b) horizontal left and right flipped part of image\n",
    "_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intersection_right_horizontal_cust, union_right_cust, symmetric_diff_right_horizontal_cust = right_horizontal_symmetry(right_horizontal_cust, left_flipped_cust)\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nRight Horizontal Part\")\n",
    "print(\"___\" *15)\n",
    "print(\"\")\n",
    "\n",
    "print(\"\\nIntersection of Image A and B: \\n\", intersection_right_horizontal_cust)\n",
    "print(\"\\nUnion of Image A and B: \\n\", union_right_cust)\n",
    "print(\"\\nSymmetric Differene of Image A and B: \\n\", symmetric_diff_right_horizontal_cust)\n",
    "\n",
    "\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nSubplot of Right Horizontal Part\")\n",
    "print(\"___\" *15)\n",
    "print(\"\")\n",
    "subplots_asymmetry(right_horizontal_cust, left_flipped_cust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_left_horizontal_cust, union_left_cust, symmetric_diff_left_horizontal_cust = left_horizontal_symmetry(left_horizontal_cust, right_flipped_cust)\n",
    "\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nLeft Horizontal Part\")\n",
    "print(\"___\" * 15)\n",
    "print(\"\")\n",
    "\n",
    "print(\"\\nIntersetion of Image D and C:\\n\", intersection_left_horizontal_cust)\n",
    "print(\"\\nUnion of Image D and C:\\n\", union_left_cust)\n",
    "print(\"\\nSymmetric Difference of Image D and C:\\n\", symmetric_diff_left_horizontal_cust)\n",
    "\n",
    "print(\"___\" * 15)\n",
    "print(\"\\nSubplot of Left Horizontal Part\")\n",
    "print(\"___\" *15)\n",
    "print(\"\")\n",
    "subplots_asymmetry(left_horizontal_cust, right_flipped_cust)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Hammoude Distance (HM): To help determine astrymmetry for the two parts\n",
    "\n",
    "_ N is the number of pixels for union of image A and B and intersection of image A and B_ \n",
    "\n",
    "The distance measure used to measure the errors between the segmented parts. HM is based on a pixel by pixel comparison of the pixels enclosed by two boundaries."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_union = np.sum(union_left_cust)\n",
    "N_intersec = np.sum(intersection_left_horizontal_cust)\n",
    "print(N_union)\n",
    "print(N_intersec)\n",
    "\n",
    "\n",
    "HM = (N_union - N_intersec)/N_union\n",
    "print(HM)"
   ]
  },
  {
   "source": [
    "## Vertical Asymmetry Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation mask flipped for vertical asymmetrical analysis of shape\n",
    "\n",
    "flipped_mask = cv2.flip(mask_img, 1)\n",
    "plt.imshow(flipped_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center points of flipped mask\n",
    "flipped_mask_center = centerpoint(flipped_mask)\n",
    "print(\"Mask: Coordinates of center point is\", flipped_mask_center)"
   ]
  },
  {
   "source": [
    "## Vertical Part of Segmentation Mask Above Central Line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part the segmentation mask vertically in two halves on y-axis by central point 218\n",
    "vertical_up = flipped_mask[:flipped_mask_center[1]:,:]\n",
    "\n",
    "\n",
    "#mirrored part \n",
    "vertical_up_flipped = np.fliplr(vertical_up)\n",
    "\n",
    "\n",
    "#asymmetry of the two halves by overlapping 'vertical up' with 'vertical up flipped'\n",
    "overlapping_up_vertical = cv2.addWeighted(vertical_up, 0.5, vertical_up_flipped, 0.5, 1.0)\n",
    "#plt.imshow(overlapping_up_vertical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 12))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(vertical_up)\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"A) Vertical Part Above Center Line \", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(vertical_up_flipped)\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"B) Vertical Part Flipped Above Center Line\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(overlapping_up_vertical)\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Vertical Asymmetry of A and B\", fontsize=12, c = 'w')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#the grey part shows the non-overlapping parts of the two images"
   ]
  },
  {
   "source": [
    "## Vertical Part of Segmentation Mask Under Central Line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part the segmentation mask vertically in two halves on y-axis by central point 218\n",
    "vertical_down = flipped_mask[flipped_mask_center[1]:,:]\n",
    "#plt.imshow(vertical_down)\n",
    "\n",
    "\n",
    "#mirrored part \n",
    "vertical_down_flipped = np.fliplr(vertical_down)\n",
    "\n",
    "#asymmetry of the two halves by overlapping 'vertical down' with 'vertical down flipped'\n",
    "overlapping_down_vertical = cv2.addWeighted(vertical_down, 0.5, vertical_down_flipped, 0.5, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 12))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(vertical_down)\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"C) Vertical Part Under Center Line \", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(vertical_down_flipped)\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"D) Vertical Part Flipped Under Center Line\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(overlapping_down_vertical)\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Vertical Asymmetry of C and D\", fontsize=12, c = 'w')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#the grey part shows the non-overlapping parts of the two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Load Data: example_ground_truth.csv and features.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = '../data/example_ground_truth.csv'\n",
    "file_features = '../features/features.csv'\n",
    "\n",
    "df = pd.read_csv(file_data)\n",
    "features = pd.read_csv(file_features)\n",
    "\n",
    "df = pd.read_csv(file_data)\n",
    "features = pd.read_csv(file_features)\n",
    "\n",
    "\n",
    "# Combine variables we want in one place\n",
    "df = df.drop(['image_id','seborrheic_keratosis'],axis=1)\n",
    "df['area'] = features['area']\n",
    "df['perimeter'] = features['perimeter']\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "source": [
    "## Data Frames for all our files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "file_features_df \n",
    "\n",
    "#melanoma\n",
    "melanoma_df\n",
    "\n",
    "#melanoma and features\n",
    "merge_feature_melanoma\n",
    "\n",
    "#non_malignant and features\n",
    "print(merge_feature_non_malignant_df)"
   ]
  },
  {
   "source": [
    "# Plots of Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Melanoma and Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melanoma\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df1 = df[['area','perimeter']]\n",
    "sns.boxplot(data=df1, width=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale the features\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Fit scaler on our data\n",
    "scaler = preprocessing.StandardScaler().fit(df1)\n",
    "\n",
    "#Apply to data itself\n",
    "df2 = scaler.transform(df1)\n",
    "\n",
    "print(df2.mean()) #small number close to 0, round of error\n",
    "print(df2.var())  #equal to 1 \n",
    "sns.boxplot(data=df2, width=0.5,fliersize=5) #we see both negative and positive values, since the mean is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Look at values#print(df2.dtype) #scaler lost df information :(\n",
    "df2 = pd.DataFrame(df2,columns=['area','perimeter'])\n",
    "\n",
    "# Look at values per class\n",
    "df2['melanoma'] = df['melanoma']\n",
    "sns.pairplot(df2, hue=\"melanoma\", height=3,diag_kind=\"hist\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"melanoma\", y=\"area\", data=df2,size=8)"
   ]
  },
  {
   "source": [
    "## Non-malignant and Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_malignant_boxplot = merge_feature_non_malignant_df[['area','perimeter']]\n",
    "sns.boxplot(data=df_non_malignant_boxplot, width=0.5)"
   ]
  },
  {
   "source": [
    "# Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data before feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some noisy data not correlated\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(df2.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "X = np.hstack((df2[['area', 'perimeter']], noise))\n",
    "y = df2['melanoma']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection with mutual information for feature scoring\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=2)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "scores = selector.scores_\n",
    "\n",
    "plt.bar(np.arange(0,22), scores, width=.2,\n",
    "        label=r'Feature score')"
   ]
  },
  {
   "source": [
    "# Train several classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Select features that had good scores on training set\n",
    "X_train1 = X_train[:, [0,1]]\n",
    "X_train2 = selector.transform(X_train)\n",
    "\n",
    "# Train a classifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1) # other hyperparameters possible\n",
    "knn1trained = knn1.fit(X_train2, y_train)\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn2trained = knn2.fit(X_train2, y_train)\n",
    "\n",
    "tree1 = DecisionTreeClassifier() # various hyperparameters\n",
    "tree1trained = tree1.fit(X_train2, y_train)\n"
   ]
  },
  {
   "source": [
    "# Evaluate classifiers on validation set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same features as before\n",
    "X_val1 = X_val[:, [0,1]]\n",
    "X_val2 = selector.transform(X_val)\n",
    "\n",
    "y_val_knn1 = knn1trained.predict(X_val2)\n",
    "y_val_knn2 = knn2trained.predict(X_val2)\n",
    "\n",
    "# Simple accuracy\n",
    "print(np.sum(y_val_knn1 == y_val) / np.size(y_val) * 100)\n",
    "print(np.sum(y_val_knn2 == y_val) / np.size(y_val) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_knn1 = accuracy_score(y_val, y_val_knn1)\n",
    "acc_knn2 = accuracy_score(y_val, y_val_knn2)\n",
    "\n",
    "print(acc_knn1)\n",
    "print(acc_knn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc1 = roc_auc_score(y_val, y_val_knn1)\n",
    "auc2 = roc_auc_score(y_val, y_val_knn2)\n",
    "\n",
    "print(auc1)\n",
    "print(auc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR REPORTING, also evaluate on test set\n",
    "X_test = X_test[:, [0,1]]\n",
    "\n",
    "y_test_knn1 = knn2trained.predict(X_test)\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_test_knn1)\n",
    "auc_test = roc_auc_score(y_test, y_test_knn1)\n",
    "\n",
    "print(acc_test)\n",
    "print(auc_test)\n",
    "\n",
    "# For small datasets these results will depend on the random seed you chose when splitting, this is why it is good to look at multiple splits/cross-validation"
   ]
  },
  {
   "source": [
    "# Scatter plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import fyp2021p3_group00_functions as util\n",
    "\n",
    "file_data = '../data/example_ground_truth.csv'\n",
    "path_image = '../data/example_image'\n",
    "path_mask = '../data/example_segmentation'\n",
    "\n",
    "file_features = '../features/features.csv'\n",
    "\n",
    "df = pd.read_csv(file_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = list(df['image_id'])\n",
    "\n",
    "# data frame for images with no diagnosis\n",
    "#df1 = df.loc[(df['melanoma'] == 0.0) & (df[\"seborrheic_keratosis\"] == 0.0)]\n",
    "\n",
    "#is_non_malignant = df1.drop([\"image_id\"], axis = 1)\n",
    "#is_non_malignant = np.array(is_non_malignant['melanoma'] + is_non_malignant['seborrheic_keratosis'])\n",
    "\n",
    "is_melanoma = np.array(df['melanoma'])\n",
    "is_keratosis = np.array(df['seborrheic_keratosis'])\n",
    " \n",
    "num_images = len(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_area = np.empty([num_images,1])\n",
    "features_area[:] = np.nan\n",
    "\n",
    "features_perimeter = np.empty([num_images,1])\n",
    "features_perimeter[:] = np.nan\n",
    "\n",
    "image_dtype = np.empty([num_images,1])\n",
    "image_dtype[:] = np.nan\n",
    "\n",
    "image_height = np.empty([num_images,1])\n",
    "image_height[:] = np.nan\n",
    "\n",
    "image_width = np.empty([num_images,1])\n",
    "image_width[:] = np.nan\n",
    "\n",
    "dimension_image = np.empty([num_images,1])\n",
    "dimension_image[:] = np.nan\n",
    "\n",
    "image_size = np.empty([num_images,1])\n",
    "image_size[:] = np.nan\n",
    "\n",
    "image_max = np.empty([num_images,1])\n",
    "image_max[:] = np.nan\n",
    "\n",
    "image_min = np.empty([num_images,1])\n",
    "image_min[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in np.arange(num_images):\n",
    "    \n",
    "    # Define filenames related to this image\n",
    "    file_image = path_image + os.sep + image_id[i] + '.jpg'\n",
    "    file_mask = path_mask + os.sep + image_id[i] + '_segmentation.png'\n",
    "    \n",
    "\n",
    "    # Read the images with these filenames\n",
    "    im = plt.imread(file_image)\n",
    "    mask = plt.imread(file_mask)\n",
    "    \n",
    "    # Measure features\n",
    "    a, p = util.measure_area_perimeter(mask)\n",
    "    \n",
    "    # Store in the variables we created before\n",
    "    features_area[i,0] = a\n",
    "    features_perimeter[i,0] = p\n",
    "\n",
    "    # Store properties of images\n",
    "    image_dtype = im.dtype\n",
    "    image_height[i,0] = im.shape[0] \n",
    "    image_width[i,0] = im.shape[1]\n",
    "    dimension_image[i,0] =  im.ndim #three layers: Red, Green, Blue\n",
    "    image_size[i,0] = im.size\n",
    "    image_max[i,0] = im.max()\n",
    "    image_min[i,0] = im.min()\n",
    "   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store these features so you can reuse them later\n",
    "feature_data = {\"image_id\": image_id, \n",
    "                \"area\": features_area.flatten(),\n",
    "                \"perimeter\": features_perimeter.flatten()\n",
    "                }\n",
    "\n",
    "df_features = pd.DataFrame(feature_data)\n",
    "df_features.to_csv(file_features, index=False) \n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe: properties of images \n",
    "properties_image = {\"image_id\": image_id,\n",
    "                    \"image_type\": image_dtype,\n",
    "                    \"image_height\": image_height.flatten(),\n",
    "                    \"image_width\": image_width.flatten(),\n",
    "                    \"dimension\": dimension_image.flatten(),\n",
    "                    \"image_size\": image_size.flatten(),\n",
    "                    \"image_max\": image_max.flatten(),\n",
    "                    \"image_min\": image_min.flatten()\n",
    "                    }\n",
    "df_properties_img = pd.DataFrame(properties_image)\n",
    "df_properties_img     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out all images that are not melanoma\n",
    "melanoma = df[df[\"melanoma\"] == 1.0]\n",
    "print(\"Total number of data for Melanoma: \",melanoma_df.shape)\n",
    "\n",
    "#filter out all images that are not keratosis\n",
    "keratosis = df[df[\"seborrheic_keratosis\"] == 1.0]\n",
    "print(\"Total number of data for Keratosis: \", keratosis.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keratosis_df = keratosis.drop([\"melanoma\"], axis = 1)\n",
    "print(keratosis_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keratosis_prop = df_properties_img.merge(keratosis_df, on='image_id', how='right')\n",
    "df_keratosis_prop"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove column for keratosis\n",
    "melanoma_df = melanoma.drop([\"seborrheic_keratosis\"], axis = 1)\n",
    "print(melanoma_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melanoma_prop = df_properties_img.merge(melanoma_df, on='image_id', how='right')\n",
    "df_melanoma_prop"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melanoma_prop_feat = df_melanoma_prop.merge(df_features, on='image_id', how='left')\n",
    "df_melanoma_prop_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keratosis_prop_feat = df_keratosis_prop.merge(df_features, on='image_id', how='left')\n",
    "df_keratosis_prop_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data you saved, then do some analysis\n",
    "df_features = pd.read_csv(file_features)\n",
    "image_id = list(df_features['image_id'])\n",
    "features_area = np.array(df_features['area'])\n",
    "features_perimeter = np.array(df_features['perimeter'])\n",
    "\n",
    "# Display the features measured in a scatterplot\n",
    "axs = util.scatter_data(features_area, features_perimeter, is_melanoma)\n",
    "axs.set_xlabel('X1 = Area')\n",
    "axs.set_ylabel('X2 = Perimeter')\n",
    "axs.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features and labels\n",
    "x = df_features.iloc[:,1:].to_numpy()\n",
    "y = is_melanoma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the features measured in a scatterplot\n",
    "axs = util.scatter_data(features_area, features_perimeter, is_keratosis)\n",
    "axs.set_xlabel('X1 = Area')\n",
    "axs.set_ylabel('X2 = Perimeter')\n",
    "axs.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FYP project 3 - introduction",
   "provenance": []
  },
  "kernelspec": {
   "name": "python392jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}