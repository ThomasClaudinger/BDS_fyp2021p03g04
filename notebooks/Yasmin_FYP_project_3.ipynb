{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yasminsarkhosh/fyp2021p3/blob/main/FYP_project_3_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fQN_SBG0idm"
   },
   "source": [
    "## Get some images and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8Nv2biGui3u",
    "outputId": "7b569744-dc4a-42b9-e7f4-373dc60a7264"
   },
   "outputs": [],
   "source": [
    "#if True:      #A weird trick needed for Google Colab\n",
    "  # Clone repository with example images \n",
    "  #!rm -rf fyp2021p3\n",
    "  #!git clone https://github.com/vcheplygina/fyp2021p3.git\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Other useful packages might be skimage or PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING IN FILE: EXAMPLE_GROUND_TRUTH.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#read file\n",
    "file_input = pd.read_csv(\"../data/example_ground_truth.csv\")\n",
    "file_input.shape\n",
    "\n",
    "#150 images in total\n",
    "#3 columns: image_id, melanoma, keratosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FRAME FOR EXAMPLE_GROUND_TRUTH FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA FRAME FOR IMAGES WITH NO DIAGNOSIS, MEANING MELANOMA AND KERATOSIS == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame for images with no diagnosis\n",
    "non_malignant_df = file_input.loc[(file_input['melanoma'] == 0.0) & (file_input[\"seborrheic_keratosis\"] == 0.0)]\n",
    "non_malignant_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR IMAGES WITH MELANOMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out all images that are not melanoma\n",
    "melanoma = file_input[file_input[\"melanoma\"] == 1.0]\n",
    "\n",
    "#remove column for keratosis\n",
    "melanoma_df = melanoma.drop([\"seborrheic_keratosis\"], axis = 1)\n",
    "melanoma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of images left\n",
    "melanoma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING IN FILE FOR FEATURES.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file features\n",
    "file_features_df = pd.read_csv(\"../features/features.csv\")\n",
    "file_features_df.shape\n",
    "\n",
    "#150 rows, 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame for features\n",
    "file_features_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data frame for features with data frame for melanoma to filter out non-related images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column 'id' to 'image_id'\n",
    "file_features_df.rename(columns={'id': 'image_id'}, inplace=True)\n",
    "\n",
    "#merge data frame for file_features_df with melanoma by column 'image_id'\n",
    "merge_feature_melanoma = file_features_df.merge(melanoma_df, on='image_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR FREATURE AND MELANOMA IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame for merged features and melanoma\n",
    "#this data frame shows only data related to melanoma \n",
    "\n",
    "merge_feature_melanoma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of data frame\n",
    "merge_feature_melanoma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME FOR FEATURE AND NO DIAGNOSIS IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_feature_non_malignant_df = file_features_df.merge(non_malignant_df, on='image_id', how='right')\n",
    "merge_feature_non_malignant_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyiqoP1MEaKZ"
   },
   "source": [
    "# Explore an image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "nWaVMWpawvjr",
    "outputId": "5b0fbd89-20e6-4d11-c8cd-a897dfb54a7a"
   },
   "outputs": [],
   "source": [
    "# Load an image and display it\n",
    "\n",
    "im = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for basic properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Properties of an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def properties_img(image):\n",
    "    print('Type of the image : ' , type(image)) \n",
    "    print('Shape of the image : {}'.format(image.shape)) \n",
    "    print('Image Hight {}'.format(image.shape[0])) \n",
    "    print('Image Width {}'.format(image.shape[1])) \n",
    "    print('Dimension of Image {}'.format(image.ndim)) #three layers: Red, Green, Blue\n",
    "\n",
    "properties_img(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_max_min(image):\n",
    "    print('Image size {}'.format(image.size)) \n",
    "    print('Maximum RGB value in this image {}'.format(image.max())) \n",
    "    print('Minimum RGB value in this image {}'.format(image.min()))\n",
    "\n",
    "RGB_max_min(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols=3, figsize=(15,5))  \n",
    "for c, ax in zip(range(3), ax):     \n",
    "     # create zero matrix        \n",
    "     split_img = np.zeros(im.shape, dtype=\"uint8\") \n",
    "     # 'dtype' by default: 'numpy.float64'  # assing each channel      \n",
    "     split_img[ :, :, c] = im[ :, :, c] # display each channel     \n",
    "     ax.imshow(split_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erosion\n",
    "\n",
    "_All the pixels near boundary will be discarded depending upon the size of kernel. Useful for removing small white noises_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/example_image/ISIC_0012099.jpg',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "plt.imshow(erosion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation\n",
    "\n",
    "_Opposite of erosion. Increases the white region in the image after erosion removes the white noises, as it also skrinks our objects. Thus, we dilate it. Also useful in joining broken parts of an object together_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(img, kernel, iterations = 1)\n",
    "plt.imshow(dilation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening\n",
    "\n",
    "_Also known as erosion followed by dilation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "plt.imshow(opening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "_Reverse of Opening. This, dilation followed by erosion. Useful in closing small holes inside the foreground objects or small black points of the object_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "plt.imshow(closing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Gradient\n",
    "\n",
    "_The difference between dilation and erosion of an image. The result will look like the outline of the object_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "plt.imshow(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StEIy91ByKqa",
    "outputId": "1391d60e-1ad1-4139-9ce6-4eb8db494b6d"
   },
   "outputs": [],
   "source": [
    "#A color image is a array with 3 dimensions (x, y, R-G-B color channels) of integers\n",
    "\n",
    "print(im.shape)\n",
    "print(im.dtype)\n",
    "\n",
    "#Other packages might wrap the image in a different class - you are allowed to use those if you want\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-dimension array of the data. \n",
    "#All of the data is the image: \n",
    "# each matrix block is a row of data, and each element within that is the pixel values in RGB-A (Red Green Blue Alpha)\n",
    "\n",
    "print(np.array(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "LvjH7_r6yyXs",
    "outputId": "762b2672-1942-46ca-8f8c-ce5e5d02f135"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get a single RGB value from the blue circle (marker used by dermatologist)\n",
    "print(im[1500,2000,:])\n",
    "\n",
    "# Show only the red channel\n",
    "plt.imshow(im[:,:,0], cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "NaFP1V3c0ezk",
    "outputId": "d309234a-2eca-4099-8f8b-9f6b70cfd122"
   },
   "outputs": [],
   "source": [
    "# Display only a part of the image\n",
    "\n",
    "im_part = im[60:120,130:220,:]\n",
    "plt.imshow(im_part)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "-YIwdyVGE_uA",
    "outputId": "52d76974-08d7-422b-d0bc-36e880774920"
   },
   "outputs": [],
   "source": [
    "# Modify the image by setting some pixels to black\n",
    "\n",
    "im_copy = im_part.copy()\n",
    "\n",
    "\n",
    "im_copy[0:10,0:10,:] = np.tile(0, [10, 10, 3])\n",
    "plt.imshow(im_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgyeEdZ40eMe"
   },
   "source": [
    "# Explore the segmentation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "294fxuQW1Lkl",
    "outputId": "49c606b2-3b05-42f0-fd0c-e92794cae9e3"
   },
   "outputs": [],
   "source": [
    "# Load the mask and display it\n",
    "\n",
    "mask = plt.imread('../data/example_segmentation/ISIC_0012099_segmentation.png')\n",
    "plt.imshow(mask, cmap='gray')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "Df3dV2UzsM4u",
    "outputId": "c357ffee-09c4-40f6-b262-a54a45cf1558"
   },
   "outputs": [],
   "source": [
    "# Show image and mask side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "axes[0].imshow(im)\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "EGheRlVIvVdS",
    "outputId": "877e38f1-beef-4d2b-be86-768d9d3bf602"
   },
   "outputs": [],
   "source": [
    "# Show the images overlayed, for this we can use PIL \n",
    "#!pip install pillow \n",
    "from PIL import Image \n",
    "\n",
    "# Load images as Image objects  \n",
    "img1 = Image.open('../data/example_image/ISIC_0012099.jpg') \n",
    "img2 = Image.open('../data/example_segmentation/ISIC_0012099_segmentation.png') \n",
    "  \n",
    "# Overlay - more options such as transparency should be available here  \n",
    "img2.paste(img1, (0,0), mask = img2) \n",
    "  \n",
    "# Display \n",
    "img2.show()  # This doesn't actually display an image in Google Colab :(\n",
    "plt.imshow(img2, cmap='gray')\n",
    "\n",
    "\n",
    "# Note that this is a single channel image\n",
    "print(img2.size)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "wahUSCWGxD7L",
    "outputId": "698df7ff-13d6-4f38-bbfe-5f2dc31e8e6a"
   },
   "outputs": [],
   "source": [
    "# Alternative: replace the non-lesion pixels\n",
    "\n",
    "img1 = im.copy()\n",
    "img1[mask==0] = 0\n",
    "  \n",
    "# Display \n",
    "plt.imshow(img1)\n",
    "\n",
    "# You can use any package you prefer, but beware you might need to convert between formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "m9OpMIoj9Noq",
    "outputId": "af666cfc-87f3-47e2-dd9e-6a45f6902d53"
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "img1 = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "gray = rgb2gray(img1)\n",
    "\n",
    "plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "SKtfGx8z-hxn",
    "outputId": "4bdf3789-969d-4e10-fdb0-4bfa164e08d9"
   },
   "outputs": [],
   "source": [
    "#plt.hist(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "tiZb_ynW_GUF",
    "outputId": "1a2476d6-eb18-4904-b820-d46f47938fc9"
   },
   "outputs": [],
   "source": [
    "img2 = gray < 120\n",
    "plt.imshow(img2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurements and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "\n",
    "mask=plt.imread('../data/example_segmentation/ISIC_0012099_segmentation.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total size of the image\n",
    "\n",
    "total = mask.shape[0] * mask.shape[1]\n",
    "print(\"total size of the image is \", total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of mask only: sum of all pixel values in the mask\n",
    "\n",
    "area = np.sum(mask)\n",
    "print(\"size of area is\", area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as percentage\n",
    "\n",
    "print(area/total*100)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement: width/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels_in_col = np.max(np.sum(mask, axis=0))\n",
    "pixels_in_row = np.max(np.sum(mask, axis=1))\n",
    "print(\"Number of pixels in column is, also known as width \\n\",pixels_in_col, '\\n')\n",
    "\n",
    "print(\"Number of pixels in row is, also known as height \\n\",pixels_in_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement: diameter at an angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "rot_im = transform.rotate(mask, 30)\n",
    "plt.imshow(rot_im, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find perimeter using morphology\n",
    "\n",
    "_perimeter is the sum of pixels on the border_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "#Structural element, that we will use as a \"brush\" on our mask\n",
    "struct_el = morphology.disk(20)\n",
    "\n",
    "print(struct_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_eroded = morphology.binary_erosion(mask, struct_el)\n",
    "\n",
    "# Show side by side\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 5))\n",
    "axes[0].imshow(mask, cmap='gray')\n",
    "axes[1].imshow(mask_eroded, cmap='gray')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Verify it's smaller\n",
    "print(area)\n",
    "print(np.sum(mask_eroded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the two masks from each other to get the border/perimeter\n",
    "\n",
    "image_perimeter = mask - mask_eroded\n",
    "\n",
    "plt.imshow(image_perimeter, cmap='gray') #The perimeter is very thin so it might be difficult to see on the screen\n",
    "\n",
    "#What is the length? \n",
    "print('The perimeter or border of the area is', np.sum(image_perimeter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your own mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with color image as grayscale\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "gray = rgb2gray(im)\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of the marker\n",
    "gray2 = gray[0:1400,:]\n",
    "plt.imshow(gray2, cmap='gray')\n",
    "\n",
    "mask2 = mask[0:1500,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at intensities of image\n",
    "#plt.hist(gray2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Threshold\n",
    "mymask = gray2 < 120  #Pixels with lower intensities will be equal to 1 in the mask\n",
    "plt.imshow(mymask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is some noise, we can get rid of it by morphological operators\n",
    "\n",
    "from skimage.morphology import opening\n",
    "\n",
    "# Opening = first EROSION, then DILATION \n",
    "\n",
    "# Erosion will get rid of hairs but also make the lesion smaller. \n",
    "# Dilation will restore the lesion (but not the hairs)\n",
    "\n",
    "struct_el = morphology.disk(5)\n",
    "opened = opening(mask2, struct_el)\n",
    "\n",
    "plt.imshow(opened, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filtering (blur)\n",
    "\n",
    "from skimage import filters\n",
    "\n",
    "blurred = filters.gaussian(mask,sigma=10)\n",
    "\n",
    "plt.imshow(blurred, cmap='gray')\n",
    "\n",
    "#What kind of values are in the image now?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold again\n",
    "\n",
    "mask2 = blurred > 0.5\n",
    "plt.imshow(mask2, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur color image - this could be useful for measuring color (variability)\n",
    "\n",
    "blurred = filters.gaussian(im,sigma=25)\n",
    "\n",
    "plt.imshow(blurred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General purpose features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many examples in https://scikit-image.org/docs/dev/api/skimage.feature.html \n",
    "\n",
    "# Crop image first\n",
    "\n",
    "im2 = im[700:1150,1250:1700,:]\n",
    "mask2 = mask[700:1150,1250:1700]\n",
    "\n",
    "\n",
    "plt.imshow(im2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian features recently available (might need to update version)\n",
    "\n",
    "# Example segmentation for microscopy image: https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_trainable_segmentation.html#sphx-glr-auto-examples-segmentation-plot-trainable-segmentation-py \n",
    "\n",
    "#!pip install scikit-image==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from skimage import feature\n",
    "from functools import partial \n",
    "\n",
    "#Extract feature images\n",
    "feat_im = feature.multiscale_basic_features(im2, multichannel=True, intensity=False, edges=False, texture=True)\n",
    "print(feat_im.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feat_im[:,:,3], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We measured X features for every pixel in the image - this is good for segmentation, but not image classification yet\n",
    "\n",
    "# For classification we need to aggregate the outputs for each feature type into one vector\n",
    "\n",
    "feat_vec, bin_edges = np.histogram(feat_im[:,:,8], bins=16)\n",
    "\n",
    "plt.bar(np.arange(0,16), feat_vec)\n",
    "print(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine bins based on intensities instead... \n",
    "# plt.hist(feat_im[:,:,8], bins='auto')     # Very slow for large images\n",
    "\n",
    "flat_im = np.ndarray.flatten(feat_im[:,:,8])\n",
    "flat_mask = np.ndarray.flatten(mask2)\n",
    "\n",
    "# Only pixels inside the mask\n",
    "flat_im = flat_im[flat_mask==1]\n",
    "\n",
    "quantile_bins = np.quantile(flat_im, np.arange(0,1,0.1))\n",
    "\n",
    "# Bins have different widths\n",
    "print(quantile_bins)\n",
    "\n",
    "#feat_vec, bin_edges = np.histogram(flat_im, bins=quantile_bins)\n",
    "print(feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that bins should be the same across images (for a particular feature). \n",
    "\n",
    "# Define bins once on \"representative image\" (how?), then use for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script for the FYP 2021 project 3\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_data = 'data/example_ground_truth.csv'\n",
    "path_image = 'data/example_image'\n",
    "path_mask = 'data/example_segmentation'\n",
    "\n",
    "file_features = 'features/features.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "im_test = cv2.imread('../data/example_image/ISIC_0012099.jpg',1)\n",
    "#plt.imshow(im_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = im_test.shape\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the width and height\n",
    "h=2000\n",
    "w=3008\n",
    "# Definig aspect ratio of a resized image\n",
    "ratio = 500.0 / w\n",
    "# Dimensions of a resized image\n",
    "dim = (500, int(h * ratio))\n",
    "# We have obtained a new image that we call resized3\n",
    "resized_2 = cv2.resize(im_test, dim)\n",
    "plt.imshow(resized_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = im_test.shape[:2]\n",
    "# Negative values of tx will shift the image to the left\n",
    "# Positive values will shift the image to the right\n",
    "# Negative values of ty will shift the image up\n",
    "# Positive values will shift the image down\n",
    "M = np.float32([[1, 0, 100], [0, 1, 50]])\n",
    "translated = cv2.warpAffine(im_test, M, (width, height))\n",
    "plt.imshow(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the image around y-axis (horizontal flipping)\n",
    "flipped_y = cv2.flip(img_crop, 1)\n",
    "plt.imshow(flipped_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the image around x-axis (vertical flipping)\n",
    "flipped_x = cv2.flip(img_crop, 0)\n",
    "plt.imshow(flipped_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the image around both axes\n",
    "flipped_both = cv2.flip(img_crop, -1)\n",
    "plt.imshow(flipped_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def hist_plt(mask):\n",
    "   # hist = plt.hist(mask)\n",
    "   # return hist\n",
    "\n",
    "\n",
    "#hist_orignal_img = hist_plt(original_img)\n",
    "#hist_flip_y = hist_plt(mask_flipped_y)\n",
    "#hist_flip_x = hist_plt(mask_flipped_x)\n",
    "#hist_flip_both = hist_plt(mask_flipped_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cropped version\n",
    "input_img = img_crop #original image\n",
    "mask_img  = mask_crop #segmentation image\n",
    "\n",
    "# select only masked area below\n",
    "masked = input_img.copy()\n",
    "masked[mask_img == 0 ] = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 12))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(input_img, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"Original Imput Image\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(mask_img, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"Segmentation Mask\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(masked, cmap=\"gray\")\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Masked Image\", fontsize=12, c = 'w')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "source": [
    "# TASK 1: ABC FEATURES - ASYMMETRY SHAPE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "img1 = plt.imread('../data/example_image/ISIC_0012099.jpg')\n",
    "gray = rgb2gray(img1)\n",
    "\n",
    "plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same images flipped vertically and horizontally \n",
    "\n",
    "original_img = rgb2gray(input_img)\n",
    "mask_flipped_y = rgb2gray(flipped_y)\n",
    "mask_flipped_x = rgb2gray(flipped_x)\n",
    "mask_flipped_both  = rgb2gray(flipped_both)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(8, 10))\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[1].imshow(mask_flipped_y, cmap='gray')\n",
    "axes[2].imshow(mask_flipped_x, cmap='gray')\n",
    "axes[3].imshow(mask_flipped_both, cmap='gray')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold: for customizing our own masks for each image\n",
    "def threshold_mask(mask):\n",
    "    custom_mask = mask < 125 #from plt.hist function\n",
    "    return custom_mask\n",
    "\n",
    "cust_mask_orignal = threshold_mask(original_img)\n",
    "cust_mask_y = threshold_mask(mask_flipped_y)\n",
    "cust_mask_x = threshold_mask(mask_flipped_x)\n",
    "cust_mask_both = threshold_mask(mask_flipped_both)\n",
    "\n",
    "\n",
    "# subplot of same flipped masked image\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(8, 10))\n",
    "axes[0].imshow(cust_mask_orignal, cmap='gray')\n",
    "axes[1].imshow(cust_mask_y, cmap='gray')\n",
    "axes[2].imshow(cust_mask_x, cmap='gray')\n",
    "axes[3].imshow(cust_mask_both, cmap='gray')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "source": [
    "## Find center points of each segmentation masked image\n",
    "_ code by Gino Franco Fazzi_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerpoint(mask):\n",
    "    borders = np.where(mask != 0) # This will return 2 arrays with the index where the pixels are ones\n",
    "    up, down, left, right = max(borders[0]), min(borders[0]), min(borders[1]), max(borders[1])\n",
    "    center = ((up+down) //2, (left + right) //2) # Tuple with the coordinates for the center of the lesion\n",
    "    return center\n",
    "\n",
    "#print(borders)\n",
    "#print(up, down, left, right)\n",
    "#print(center)\n",
    "\n",
    "center_original = centerpoint(mask_img)\n",
    "\n",
    "#center_flip_y = centerpoint(mask_flipped_y)\n",
    "#center_flip_x = centerpoint(mask_flipped_x)\n",
    "#center_flip_both = centerpoint(mask_flipped_both)\n",
    "\n",
    "print('Center point coordinates of masked image is:', center_original)\n",
    "\n",
    "#print('Coordinates for the center:', center_flip_y)\n",
    "#print('Coordinates for the center:', center_flip_x)\n",
    "#print('Coordinates for the center:', center_flip_both)"
   ]
  },
  {
   "source": [
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Original image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img[:,center_original[0]:]\n",
    "plt.imshow(original_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img[:,center_original[0]:]\n",
    "plt.imshow(mask_img)"
   ]
  },
  {
   "source": [
    "## Horizontal Asymmetry Analysis "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Left part of center line\n",
    "left_horizontal_img = mask_img[:,0:center_original[0]+1]\n",
    "\n",
    "# right part mirrored over the center line\n",
    "right_horizontal_mirrored_img = np.fliplr(mask_img)[:,0:center_original[0]+1]\n",
    "\n",
    "overlapping_left_horizontal = cv2.addWeighted(left_horizontal_img, 0.5, right_horizontal_mirrored_img, 0.5, 1.0)\n",
    "#plt.imshow(overlapping_left_horizontal)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6, 8))\n",
    "\n",
    "\n",
    "ax = axes.flatten()\n",
    "ax[0].imshow(left_horizontal_img, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"A: Left Horizontal Part of Image\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(right_horizontal_mirrored_img, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"B: Right Horizontal Mirrored Part of Image\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(overlapping_left_horizontal, cmap=\"gray\")\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Intersection of A and B:\\nGray area are non-overlaps\", fontsize=12, c = 'w')\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=2.0, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Subplot: Right part of center line and left part mirrored over center line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right part of the center line\n",
    "right_horizontal_img = mask_img[:,center_original[0]:]\n",
    "\n",
    "# Left part mirrored over the center line\n",
    "left_horizontal_mirrored_img = np.fliplr(mask_img)[:,center_original[0]:]\n",
    "\n",
    "overlapping_right_horizontal = cv2.addWeighted(right_horizontal_img, 0.5, left_horizontal_mirrored_img, 0.5, 1.0)\n",
    "#plt.imshow(overlapping_left_horizontal)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6, 8))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(right_horizontal_img, cmap=\"gray\")\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"C: Right Horizontal Part of Image\", fontsize=10, c = 'w')\n",
    "\n",
    "ax[1].imshow(left_horizontal_mirrored_img, cmap=\"gray\")\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"D: Left Horizontal Mirrored Part of Image\", fontsize=10, c = 'w')\n",
    "\n",
    "ax[2].imshow(overlapping_right_horizontal, cmap=\"gray\")\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Intersection of C and D:\\nGray area are non-overlaps\", fontsize=10, c = 'w')\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=1.5, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "plt.show()\n",
    "\n",
    "# Left part plus the right part - see below\n",
    "# The white part of the figure are where the two parts intersect (overlapping)\n",
    "# The gray part is where the figures are non-overlapping"
   ]
  },
  {
   "source": [
    "## Symmetric area of: \n",
    "\n",
    "_ \n",
    "a) the right and left mirrored part of the center line and \n",
    "b) the left and right mirrored part of the center line \n",
    "_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "def find_right_horizontal_symmetry(right_horizontal_img, left_horizontal_mirrored_img):\n",
    "    right_horizontal = right_horizontal_img + left_horizontal_mirrored_img\n",
    "    symmetric_area_right_horizontal = np.count_nonzero(right_horizontal)\n",
    "    return right_horizontal, symmetric_area_right_horizontal\n",
    "\n",
    "right_horizontal, symmetric_area_right_horizontal = find_right_horizontal_symmetry(right_horizontal_img, left_horizontal_mirrored_img)\n",
    "\n",
    "\n",
    "print(\"Symmetric area - Horizontal: Right and Left Mirrored Part: \\n\", symmetric_area_right_horizontal)\n",
    "\n",
    "# b)\n",
    "def find_left_horizontal_symmetry(left_horizontal_img, right_horizontal_mirrored_img):\n",
    "    left_horizontal = left_horizontal_img + right_horizontal_mirrored_img\n",
    "    symmetric_area_left_horizontal = np.count_nonzero(left_horizontal)\n",
    "    return left_horizontal, symmetric_area_left_horizontal\n",
    "\n",
    "left_horizontal, symmetric_area_left_horizontal = find_left_horizontal_symmetry(left_horizontal_img, right_horizontal_mirrored_img)\n",
    "\n",
    "print(\"\\nSymmetric area - Horizontal: Left and Right Mirrored Part: \\n\", symmetric_area_left_horizontal)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Subplots of a) and b): visualization of overlapping and non-overlapping parts of images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_horizontal_asymmetry(overlapping_left_horizontal, overlapping_right_horizontal):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 8))\n",
    "    ax = axes.flatten()\n",
    "\n",
    "    ax[0].imshow(overlapping_left_horizontal)\n",
    "    ax[0].set_axis_off()\n",
    "    ax[0].set_title(\"Asymmetry - Horizontal: Right of Center Line \", fontsize=10, c = 'w')\n",
    "\n",
    "    ax[1].imshow(overlapping_right_horizontal)\n",
    "    ax[1].set_axis_off()\n",
    "    ax[1].set_title(\"Asymmetry - Horizontal: Left of Center Line\", fontsize=10, c = 'w')\n",
    "\n",
    "    return \n",
    "\n",
    "subplot_horizontal_asymmetry(overlapping_left_horizontal, overlapping_right_horizontal)\n",
    "# Left part plus the right part - see below\n",
    "# The white part of the figure are where the two parts intersect (overlapping)\n",
    "# The gray part is where the figures are non-overlapping"
   ]
  },
  {
   "source": [
    "## Size of area: accordingly to center line\n",
    "\n",
    "_We will here look at each part: right, left, right_mirrored and left_mirrored parts of the segmentation mask image, and find size of each part seperately_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of mask only: sum of all pixel values in the mask\n",
    "\n",
    "def size_mask_centerline(right_horizontal_img, left_horizontal_img, right_horizontal_mirrored_img, left_horizontal_mirrored_img):\n",
    "    area_right = np.count_nonzero(right_horizontal_img)\n",
    "    #print(f'Size of masked area left of center line is {area_right: 22d}')\n",
    "\n",
    "    area_left = np.count_nonzero(left_horizontal_img)\n",
    "    #print(f'Size of masked area left of center line is {area_left: 22d}')\n",
    "\n",
    "    area_right_mirrored = np.count_nonzero(right_horizontal_mirrored_img)\n",
    "    #print(f'Size of masked area right mirrored over center line is {area_right_mirrored: 10d}')\n",
    "\n",
    "    area_left_mirrored = np.count_nonzero(left_horizontal_mirrored_img)\n",
    "    #print(f'Size of masked area left mirrored over center line is  {area_left_mirrored: 10d}')\n",
    "\n",
    "    return area_right, area_left, area_right_mirrored, area_left_mirrored\n",
    "    \n",
    "\n",
    "size_mask_values = list(size_mask_centerline(right_horizontal_img, left_horizontal_img, right_horizontal_mirrored_img, left_horizontal_mirrored_img))\n",
    "\n",
    "\n",
    "#list of names for the different parts of the center line\n",
    "name_key = ['right', 'left', 'right_mirrored', 'left_mirrored']\n",
    "\n",
    "# dictionary where key is the name of the part and value is an integer of mask size\n",
    "res = {name_key[i]: size_mask_values[i] for i in range(len(name_key))}\n",
    "\n",
    "# display name and value of each part in the mask\n",
    "for key in res.items():\n",
    "    print('\\nSize of masked area over center line is:\\n', key)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Vertical Asymmetry Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation mask flipped for vertical asymmetrical analysis of shape\n",
    "\n",
    "flipped_mask = cv2.flip(mask_img, 1)\n",
    "plt.imshow(flipped_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center points of flipped mask\n",
    "flipped_mask_center = centerpoint(flipped_mask)\n",
    "print(\"Mask: Coordinates of center point is\", flipped_mask_center)"
   ]
  },
  {
   "source": [
    "## Vertical Part of Segmentation Mask Above Central Line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part the segmentation mask vertically in two halves on y-axis by central point 218\n",
    "vertical_up = flipped_mask[:200,:,:flipped_mask_center[1]]\n",
    "\n",
    "#mirrored part \n",
    "vertical_up_flipped = np.fliplr(vertical_up)[:200,:,:flipped_mask_center[1]]\n",
    "\n",
    "\n",
    "#asymmetry of the two halves by overlapping 'vertical up' with 'vertical up flipped'\n",
    "overlapping_up_vertical = cv2.addWeighted(vertical_up, 0.5, vertical_up_flipped, 0.5, 1.0)\n",
    "#plt.imshow(overlapping_up_vertical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 12))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(vertical_up)\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"A) Vertical Part Above Center Line \", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(vertical_up_flipped)\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"B) Vertical Part Flipped Above Center Line\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(overlapping_up_vertical)\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Vertical Asymmetry of A and B\", fontsize=12, c = 'w')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#the grey part shows the non-overlapping parts of the two images"
   ]
  },
  {
   "source": [
    "## Vertical Part of Segmentation Mask Under Central Line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part the segmentation mask vertically in two halves on y-axis by central point 218\n",
    "vertical_down = flipped_mask[200:,:,:flipped_mask_center[1]]\n",
    "#plt.imshow(vertical_down)\n",
    "\n",
    "#mirrored part \n",
    "vertical_down_flipped = np.fliplr(vertical_down)[:,:,:flipped_mask_center[1]]\n",
    "#plt.imshow(vertical_down_flipped)\n",
    "\n",
    "#asymmetry of the two halves by overlapping 'vertical down' with 'vertical down flipped'\n",
    "overlapping_down_vertical = cv2.addWeighted(vertical_down, 0.5, vertical_down_flipped, 0.5, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(14, 12))\n",
    "ax = axes.flatten()\n",
    "\n",
    "ax[0].imshow(vertical_down)\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title(\"C) Vertical Part Under Center Line \", fontsize=12, c = 'w')\n",
    "\n",
    "ax[1].imshow(vertical_down_flipped)\n",
    "ax[1].set_axis_off()\n",
    "ax[1].set_title(\"D) Vertical Part Flipped Under Center Line\", fontsize=12, c = 'w')\n",
    "\n",
    "ax[2].imshow(overlapping_down_vertical)\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_title(\"Vertical Asymmetry of C and D\", fontsize=12, c = 'w')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#the grey part shows the non-overlapping parts of the two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Load Data: example_ground_truth.csv and features.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = '../data/example_ground_truth.csv'\n",
    "file_features = '../features/features.csv'\n",
    "\n",
    "df = pd.read_csv(file_data)\n",
    "features = pd.read_csv(file_features)\n",
    "\n",
    "df = pd.read_csv(file_data)\n",
    "features = pd.read_csv(file_features)\n",
    "\n",
    "\n",
    "# Combine variables we want in one place\n",
    "df = df.drop(['image_id','seborrheic_keratosis'],axis=1)\n",
    "df['area'] = features['area']\n",
    "df['perimeter'] = features['perimeter']\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "source": [
    "## Data Frames for all our files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "file_features_df \n",
    "\n",
    "#melanoma\n",
    "melanoma_df\n",
    "\n",
    "#melanoma and features\n",
    "merge_feature_melanoma\n",
    "\n",
    "#non_malignant and features\n",
    "print(merge_feature_non_malignant_df)"
   ]
  },
  {
   "source": [
    "# Plots of Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Melanoma and Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melanoma\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df1 = df[['area','perimeter']]\n",
    "sns.boxplot(data=df1, width=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale the features\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Fit scaler on our data\n",
    "scaler = preprocessing.StandardScaler().fit(df1)\n",
    "\n",
    "#Apply to data itself\n",
    "df2 = scaler.transform(df1)\n",
    "\n",
    "print(df2.mean()) #small number close to 0, round of error\n",
    "print(df2.var())  #equal to 1 \n",
    "sns.boxplot(data=df2, width=0.5,fliersize=5) #we see both negative and positive values, since the mean is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Look at values#print(df2.dtype) #scaler lost df information :(\n",
    "df2 = pd.DataFrame(df2,columns=['area','perimeter'])\n",
    "\n",
    "# Look at values per class\n",
    "df2['melanoma'] = df['melanoma']\n",
    "sns.pairplot(df2, hue=\"melanoma\", height=3,diag_kind=\"hist\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"melanoma\", y=\"area\", data=df2,size=8)"
   ]
  },
  {
   "source": [
    "## Non-malignant and Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_malignant_boxplot = merge_feature_non_malignant_df[['area','perimeter']]\n",
    "sns.boxplot(data=df_non_malignant_boxplot, width=0.5)"
   ]
  },
  {
   "source": [
    "# Feature Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data before feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some noisy data not correlated\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(df2.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "X = np.hstack((df2[['area', 'perimeter']], noise))\n",
    "y = df2['melanoma']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection with mutual information for feature scoring\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=2)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "scores = selector.scores_\n",
    "\n",
    "plt.bar(np.arange(0,22), scores, width=.2,\n",
    "        label=r'Feature score')"
   ]
  },
  {
   "source": [
    "# Train several classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Select features that had good scores on training set\n",
    "X_train1 = X_train[:, [0,1]]\n",
    "X_train2 = selector.transform(X_train)\n",
    "\n",
    "# Train a classifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1) # other hyperparameters possible\n",
    "knn1trained = knn1.fit(X_train2, y_train)\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn2trained = knn2.fit(X_train2, y_train)\n",
    "\n",
    "tree1 = DecisionTreeClassifier() # various hyperparameters\n",
    "tree1trained = tree1.fit(X_train2, y_train)\n"
   ]
  },
  {
   "source": [
    "# Evaluate classifiers on validation set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same features as before\n",
    "X_val1 = X_val[:, [0,1]]\n",
    "X_val2 = selector.transform(X_val)\n",
    "\n",
    "y_val_knn1 = knn1trained.predict(X_val2)\n",
    "y_val_knn2 = knn2trained.predict(X_val2)\n",
    "\n",
    "# Simple accuracy\n",
    "print(np.sum(y_val_knn1 == y_val) / np.size(y_val) * 100)\n",
    "print(np.sum(y_val_knn2 == y_val) / np.size(y_val) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_knn1 = accuracy_score(y_val, y_val_knn1)\n",
    "acc_knn2 = accuracy_score(y_val, y_val_knn2)\n",
    "\n",
    "print(acc_knn1)\n",
    "print(acc_knn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc1 = roc_auc_score(y_val, y_val_knn1)\n",
    "auc2 = roc_auc_score(y_val, y_val_knn2)\n",
    "\n",
    "print(auc1)\n",
    "print(auc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR REPORTING, also evaluate on test set\n",
    "X_test = X_test[:, [0,1]]\n",
    "\n",
    "y_test_knn1 = knn2trained.predict(X_test)\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_test_knn1)\n",
    "auc_test = roc_auc_score(y_test, y_test_knn1)\n",
    "\n",
    "print(acc_test)\n",
    "print(auc_test)\n",
    "\n",
    "# For small datasets these results will depend on the random seed you chose when splitting, this is why it is good to look at multiple splits/cross-validation"
   ]
  },
  {
   "source": [
    "# Scatter plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import fyp2021p3_group00_functions as util\n",
    "\n",
    "file_data = '../data/example_ground_truth.csv'\n",
    "path_image = '../data/example_image'\n",
    "path_mask = '../data/example_segmentation'\n",
    "\n",
    "file_features = '../features/features.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_data)\n",
    "\n",
    "\n",
    "image_id = list(df['image_id'])\n",
    "is_melanoma = np.array(df['melanoma'])\n",
    "\n",
    "df_features = pd.read_csv(file_features)\n",
    "\n",
    "image_id = list(df_features['id'])\n",
    "\n",
    "features_area = np.array(df_features['area'])\n",
    "features_perimeter = np.array(df_features['perimeter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scatter_data(x1, x2, y, ax=None):\n",
    "    # scatter_data displays a scatterplot of featuress x1 and x2, and gives each point\n",
    "    # a different color based on its label in y\n",
    "\n",
    "    class_labels, indices1, indices2 = np.unique(y, return_index=True, return_inverse=True)\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.grid()\n",
    "\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(class_labels)))\n",
    "    for i, c in zip(np.arange(len(class_labels)), colors):\n",
    "        idx2 = indices2 == class_labels[i]\n",
    "        lbl = 'Class ' + str(i)\n",
    "        ax.scatter(x1[idx2], x2[idx2], color=c, label=lbl)\n",
    "\n",
    "    return ax\n",
    "\n",
    "x1 = features_area\n",
    "x2 = features_perimeter\n",
    "y = is_melanoma\n",
    "\n",
    "scatter_data(x1, x2, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = list(df['image_id'])\n",
    "is_melanoma = np.array(df['melanoma'])\n",
    "is_keratosis = np.array(df['seborrheic_keratosis'])\n",
    "\n",
    "\n",
    "num_images = len(image_id)\n",
    "\n",
    "features_area = np.empty([num_images,1])\n",
    "features_area[:] = np.nan\n",
    "features_perimeter = np.empty([num_images,1])\n",
    "features_perimeter[:] = np.nan\n",
    "\n",
    "for i in np.arange(num_images):\n",
    "    \n",
    "    # Define filenames related to this image\n",
    "    file_image = path_image + os.sep + image_id[i] + '.jpg'\n",
    "    file_mask = path_mask + os.sep + image_id[i] + '_segmentation.png'\n",
    "    \n",
    "    # Read the images with these filenames\n",
    "    im = plt.imread(file_image)\n",
    "    mask = plt.imread(file_mask)\n",
    "    \n",
    "    # Measure features\n",
    "    a, p = util.measure_area_perimeter(mask)\n",
    "    \n",
    "    # Store in the variables we created before\n",
    "    features_area[i,0] = a\n",
    "    features_perimeter[i,0] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FYP project 3 - introduction",
   "provenance": []
  },
  "kernelspec": {
   "name": "python392jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}